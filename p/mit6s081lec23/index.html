<!DOCTYPE html>
<html lang="zh-cn" dir="ltr">
    <head><meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'><meta name='description' content="RCU">
<title>MIT6S081Lec23</title>

<link rel='canonical' href='https://echudet.github.io/p/mit6s081lec23/'>

<link rel="stylesheet" href="/scss/style.min.a7f637593c1d99350f36f270c9abc65cf39ec34b45847eb2fa40efef51b94c92.css"><meta property='og:title' content="MIT6S081Lec23">
<meta property='og:description' content="RCU">
<meta property='og:url' content='https://echudet.github.io/p/mit6s081lec23/'>
<meta property='og:site_name' content='echudet'>
<meta property='og:type' content='article'><meta property='article:section' content='Post' /><meta property='article:published_time' content='2024-10-08T22:02:50&#43;08:00'/><meta property='article:modified_time' content='2024-11-12T12:44:05&#43;08:00'/>
<meta name="twitter:title" content="MIT6S081Lec23">
<meta name="twitter:description" content="RCU">
    <link rel="shortcut icon" href="/timer.ico" />

    </head>
    <body class="
    article-page
    ">
    <script>
        (function() {
            const colorSchemeKey = 'StackColorScheme';
            if(!localStorage.getItem(colorSchemeKey)){
                localStorage.setItem(colorSchemeKey, "auto");
            }
        })();
    </script><script>
    (function() {
        const colorSchemeKey = 'StackColorScheme';
        const colorSchemeItem = localStorage.getItem(colorSchemeKey);
        const supportDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches === true;

        if (colorSchemeItem == 'dark' || colorSchemeItem === 'auto' && supportDarkMode) {
            

            document.documentElement.dataset.scheme = 'dark';
        } else {
            document.documentElement.dataset.scheme = 'light';
        }
    })();
</script>
<div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky ">
    <button class="hamburger hamburger--spin" type="button" id="toggle-menu" aria-label="切换菜单">
        <span class="hamburger-box">
            <span class="hamburger-inner"></span>
        </span>
    </button>

    <header>
        
            
            <figure class="site-avatar">
                <a href="/">
                
                    
                    
                    
                        
                        <img src="/img/avatar_hu11199958555974308744.png" width="300"
                            height="300" class="site-logo" loading="lazy" alt="Avatar">
                    
                
                </a>
                
                    <span class="emoji">⌨️</span>
                
            </figure>
            
        
        
        <div class="site-meta">
            <h1 class="site-name"><a href="/">echudet</a></h1>
            <h2 class="site-description">探索编程的学生一枚</h2>
        </div>
    </header><ol class="menu-social">
            
                <li>
                    <a 
                        href='https://github.com/EchudeT'
                        target="_blank"
                        title="GitHub"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5" />
</svg>



                        
                    </a>
                </li>
            
                <li>
                    <a 
                        href='https://twitter.com'
                        target="_blank"
                        title="Twitter"
                        rel="me"
                    >
                        
                        
                            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
  <path d="M22 4.01c-1 .49 -1.98 .689 -3 .99c-1.121 -1.265 -2.783 -1.335 -4.38 -.737s-2.643 2.06 -2.62 3.737v1c-3.245 .083 -6.135 -1.395 -8 -4c0 0 -4.182 7.433 4 11c-1.872 1.247 -3.739 2.088 -6 2c3.308 1.803 6.913 2.423 10.034 1.517c3.58 -1.04 6.522 -3.723 7.651 -7.742a13.84 13.84 0 0 0 .497 -3.753c-.002 -.249 1.51 -2.772 1.818 -4.013z" />
</svg>



                        
                    </a>
                </li>
            
        </ol><ol class="menu" id="main-menu">
        
        
        
        <li >
            <a href='/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <polyline points="5 12 3 12 12 3 21 12 19 12" />
  <path d="M5 12v7a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-7" />
  <path d="M9 21v-6a2 2 0 0 1 2 -2h2a2 2 0 0 1 2 2v6" />
</svg>



                
                <span>主页</span>
            </a>
        </li>
        
        
        <li >
            <a href='/%E5%85%B3%E4%BA%8E/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="7" r="4" />
  <path d="M6 21v-2a4 4 0 0 1 4 -4h4a4 4 0 0 1 4 4v2" />
</svg>



                
                <span>关于</span>
            </a>
        </li>
        
        
        <li >
            <a href='/archives/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <rect x="3" y="4" width="18" height="4" rx="2" />
  <path d="M5 8v10a2 2 0 0 0 2 2h10a2 2 0 0 0 2 -2v-10" />
  <line x1="10" y1="12" x2="14" y2="12" />
</svg>



                
                <span>档案</span>
            </a>
        </li>
        
        
        <li >
            <a href='/search/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="10" cy="10" r="7" />
  <line x1="21" y1="21" x2="15" y2="15" />
</svg>



                
                <span>搜索</span>
            </a>
        </li>
        
        
        <li >
            <a href='/links/' >
                
                
                
                    <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M10 14a3.5 3.5 0 0 0 5 0l4 -4a3.5 3.5 0 0 0 -5 -5l-.5 .5" />
  <path d="M14 10a3.5 3.5 0 0 0 -5 0l-4 4a3.5 3.5 0 0 0 5 5l.5 -.5" />
</svg>



                
                <span>Links</span>
            </a>
        </li>
        
        <li class="menu-bottom-section">
            <ol class="menu">

                
                    <li id="dark-mode-toggle">
                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="8" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="16" cy="12" r="2" />
  <rect x="2" y="6" width="20" height="12" rx="6" />
</svg>



                        <span>暗色模式</span>
                    </li>
                
            </ol>
        </li>
    </ol>
</aside>

    <aside class="sidebar right-sidebar sticky">
        
            
                
    <section class="widget archives">
        <div class="widget-icon">
            <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <line x1="5" y1="9" x2="19" y2="9" />
  <line x1="5" y1="15" x2="19" y2="15" />
  <line x1="11" y1="4" x2="7" y2="20" />
  <line x1="17" y1="4" x2="13" y2="20" />
</svg>



        </div>
        <h2 class="widget-title section-title">目录</h2>
        
        <div class="widget--toc">
            <nav id="TableOfContents">
  <ol>
    <li><a href="#课前预习">课前预习</a></li>
    <li><a href="#论文速览">论文速览</a></li>
    <li><a href="#rcu的工作原理"><strong>RCU的工作原理</strong></a></li>
    <li><a href="#synchronize_rcu">synchronize_rcu</a></li>
    <li><a href="#关于-synchronize_rcu-的深入探讨">关于 <code>synchronize_rcu</code> 的深入探讨</a></li>
    <li><a href="#异步版本的-synchronize_rcu-call_rcu">异步版本的 <code>synchronize_rcu</code>: <code>call_rcu</code></a></li>
    <li><a href="#linux-nmi">Linux NMI</a></li>
    <li><a href="#传统锁与-rcu">传统锁与 RCU</a></li>
    <li><a href="#linux-的-slab-分配器">Linux 的 slab 分配器</a></li>
    <li><a href="#类型安全">类型安全</a></li>
    <li><a href="#类型安全内存的防护传统方式与rcu机制的比较">类型安全内存的防护：传统方式与RCU机制的比较</a></li>
    <li><a href="#reverse-mapping">reverse-mapping</a></li>
    <li><a href="#内存回收memory-reclamation">内存回收（Memory Reclamation）</a></li>
    <li><a href="#发布-订阅模型-publish-subscribe">发布-订阅模型 (Publish-Subscribe)</a></li>
    <li><a href="#cache-miss">Cache miss</a></li>
    <li><a href="#间接访问indirection">间接访问（indirection）</a></li>
    <li><a href="#正课部分">正课部分</a></li>
    <li><a href="#使用锁带来的问题">使用锁带来的问题</a></li>
    <li><a href="#读写锁-read-write-lock">读写锁 (Read-Write Lock)</a></li>
    <li><a href="#rcu实现1---基本实现">RCU实现(1) - 基本实现</a></li>
    <li><a href="#rcu实现2---memory-barrier">RCU实现(2) - Memory barrier</a></li>
    <li><a href="#rcu实现3---读写规则">RCU实现(3) - 读写规则</a></li>
    <li><a href="#rcu用例代码">RCU用例代码</a></li>
  </ol>
</nav>
        </div>
    </section>

            
        
    </aside>


            <main class="main full-width">
    <article class="main-article">
    <header class="article-header">

    <div class="article-details">
    
    <header class="article-category">
        
            <a href="/categories/mit6s081/" >
                Mit6s081
            </a>
        
            <a href="/categories/os/" >
                Os
            </a>
        
    </header>
    

    <div class="article-title-wrapper">
        <h2 class="article-title">
            <a href="/p/mit6s081lec23/">MIT6S081Lec23</a>
        </h2>
    
        
        <h3 class="article-subtitle">
            RCU
        </h3>
        
    </div>

    
    
    
    
    <footer class="article-time">
        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <path d="M11.795 21h-6.795a2 2 0 0 1 -2 -2v-12a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v4" />
  <circle cx="18" cy="18" r="4" />
  <path d="M15 3v4" />
  <path d="M7 3v4" />
  <path d="M3 11h16" />
  <path d="M18 16.496v1.504l1 1" />
</svg>
                <time class="article-time--published">2024-10-08</time>
            </div>
        

        
            <div>
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time class="article-time--reading">
                    阅读时长: 73 分钟
                </time>
            </div>
        <div class="article-lastmod">
                <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



                <time>
                    Nov 12, 2024 12:44 &#43;0800
                </time>
            </div></footer>
    

    
</div>

</header>

    <section class="article-content">
    
    
    <h1 id="lecture-23-rcu">Lecture 23 RCU
</h1><h2 id="课前预习">课前预习
</h2><h2 id="论文速览">论文速览
</h2><p>在Introduction (简介)部分，介绍了<code>Read-Copy Update (RCU)</code>作为Linux内核中一种高性能的同步机制。它支持并发的读写操作，且自引入以来，RCU的使用不断扩大，成为Linux内核中的关键组件。文章回顾了RCU的发展背景，并说明了其高效性能在内核中带来的巨大优势。</p>
<p>在RCU Requirements (RCU要求)部分提到，RCU在Linux内核中的实现需要满足三个关键要求：支持更新时的并发读取；低计算和存储开销；确定的操作完成时间，尤其是在实时响应和系统工程方面具有重要意义。</p>
<p>在RCU Design (RCU设计)部分，详细介绍了RCU的设计，包括核心的两个基本操作：</p>
<ul>
<li><strong>RCU读侧临界区</strong>：用来保证线程可以安全读取数据结构。</li>
<li><strong>RCU同步</strong>：用来确保所有并发的读操作完成后再进行更新操作。通过这些机制，RCU允许多线程并发读取数据，同时其他线程可以更新数据。</li>
</ul>
<p>在Using RCU (RCU的使用)部分，详细阐述了RCU在Linux内核中的多种使用模式：</p>
<ul>
<li><strong>4.1 Wait for Completion (等待操作完成)</strong>：RCU用于等待预先存在的操作完成，以确保安全地移除数据。</li>
<li><strong>4.2 Reference Counting (引用计数)</strong>：RCU作为引用计数的替代方案，提供了更高效的内存释放机制。</li>
<li><strong>4.3 Type Safe Memory (类型安全内存)</strong>：确保在多线程操作中，被释放的内存不会被错误地重新分配。</li>
<li><strong>4.4 Publish-Subscribe (发布-订阅模式)</strong>：提供一种安全发布数据的方式，确保并发读取操作安全。</li>
<li><strong>4.5 Read-Write Lock Alternative (读写锁的替代方案)</strong>：RCU作为读写锁的高效替代方案，在并发读取场景下提供了更好的性能。</li>
</ul>
<p>在Algorithmic Transformations (算法转换)部分，讨论了为了适应RCU而需要进行的几种常见算法转换：</p>
<ul>
<li><strong>5.1 Impose Level of Indirection (引入间接层次)</strong>：通过间接访问数据结构来保证数据的一致性。</li>
<li><strong>5.2 Mark Obsolete Objects (标记过时对象)</strong>：对数据对象进行标记，防止读取到已过时的数据。</li>
<li><strong>5.3 Retry Readers (读者重试)</strong>：当检测到数据已被更新时，读线程可以选择重试操作。</li>
</ul>
<p>在RCU Usage Statistics (RCU使用统计)部分，提供了RCU在不同Linux子系统中的使用统计数据，展示了自RCU引入以来的使用增长趋势，尤其是在网络栈、System V IPC以及其他内核子系统中的广泛应用。</p>
<p>在Related Work (相关工作)部分，作者回顾了与RCU相关的其他并发控制机制，包括类似RCU的机制和不同的内存回收技术。这些机制在不同操作系统中被广泛使用。</p>
<p>在Conclusions (结论)部分，总结了RCU在Linux内核中作为一种关键同步机制的成功，讨论了RCU的多种应用模式和转换方法，并展望了未来在内核中更多RCU应用的可能性。</p>
<hr>
<h2 id="rcu的工作原理"><strong>RCU的工作原理</strong>
</h2><p><strong>RCU在Linux内核中的设计与工作原理</strong>，核心在于两个基本操作：</p>
<ol>
<li><strong>RCU读侧临界区</strong>：使用<code>rcu_read_lock</code>和<code>rcu_read_unlock</code>实现。进入读侧临界区时，线程调用<code>rcu_read_lock</code>以防止被抢占，确保其对共享数据的读取不会与其他更新操作冲突。当线程退出临界区时调用<code>rcu_read_unlock</code>。</li>
<li><strong>RCU同步</strong>：用<code> synchronize_rcu</code>实现。这个操作确保在调用时所有正在执行的读侧临界区已结束，但不阻止新的读操作。该操作常用于等待之前的读操作完成，从而安全地进行数据更新或释放内存。</li>
</ol>
<p>假设我们需要从目录缓存中删除一个<code>dentry</code>结构体（文件目录缓存项）。删除过程包含以下步骤：</p>
<ul>
<li>一个线程在读取<code>dentry</code>时会进入RCU读侧临界区，使用<code>rcu_read_lock</code>保护数据读取。</li>
<li>当需要删除<code>dentry</code>时，系统首先将其从目录缓存中移除（但不立即释放内存），然后调用<code>synchronize_rcu</code>等待当前所有对该<code>dentry</code>的读取操作完成。</li>
<li>在<code>synchronize_rcu</code>返回后，系统可以安全地释放这个<code>dentry</code>的内存，因为所有之前的读操作都已完成。</li>
</ul>
<p>这种方法通过允许读者线程在临界区内访问数据，而更新线程可以异步等待所有读操作完成，从而避免锁定导致的性能损失和死锁。</p>
<p>这种设计实现了RCU对高性能、并发访问和低开销的要求。在Linux内核中，这种机制广泛应用于诸如网络栈和文件系统等高并发场景。</p>
<hr>
<h2 id="synchronize_rcu">synchronize_rcu
</h2><p>在Linux内核中，<code>synchronize_rcu</code>是一个重要的同步原语，用于确保所有现存的RCU读操作完成之后才继续执行接下来的更新或内存释放操作。下面我将详细解释<code>synchronize_rcu</code>的工作机制、使用场景及其背后的工作原理，并通过示例来说明其实际应用。</p>
<p>在RCU (Read-Copy-Update) 中，读者线程可以无锁地访问共享数据，而写者线程在更新数据时则需要等待所有并发的读者线程完成当前的读取操作，以避免数据不一致或内存被过早释放。</p>
<p>当写者线程想要修改或删除某个共享数据结构时，它不能直接对数据结构进行操作，因为可能有其他线程正在读取这个数据结构。为了避免这种情况，写者线程需要调用<code>synchronize_rcu</code>，该函数确保在它返回之前，所有使用过旧版本数据的读者线程都已经完成它们的临界区。</p>
<p><code>synchronize_rcu</code>的基本工作流程是等待所有处理器（CPU）执行至少一次上下文切换。每个RCU的读侧临界区通过<code>rcu_read_lock</code>和<code>rcu_read_unlock</code>进行标记，当<code>rcu_read_lock</code>被调用时，它会禁止内核调度器抢占线程。这样，在临界区内，读者线程可以安全地读取数据结构，而不必担心写操作导致的并发问题。</p>
<p><code>synchronize_rcu</code>不会阻止新的RCU读侧临界区的进入，而是等待所有当前活跃的RCU读侧临界区结束。一旦所有读者线程退出临界区，<code>synchronize_rcu</code>函数就会返回，此时可以保证之前版本的数据不会再被读取，从而可以安全地进行数据更新或内存释放。</p>
<p>简化版的实现示例：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">synchronize_rcu</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="nf">for_each_cpu</span><span class="p">(</span><span class="kt">int</span> <span class="n">cpu</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nf">run_on</span><span class="p">(</span><span class="n">cpu</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>这个伪代码的基本含义是让调用线程在每个CPU上运行一次，以确保所有CPU上的上下文切换已完成。这种设计避免了在每个读者线程之间进行显式的通信，极大地简化了同步机制的复杂性和性能开销。</p>
<p><code>synchronize_rcu</code>主要用于以下几种典型场景：</p>
<ol>
<li><strong>等待数据更新安全完成</strong>：当写者线程想要删除或更新一个数据结构时，它会首先从共享数据结构中移除旧数据（但不立即释放内存），并调用<code>synchronize_rcu</code>确保所有并发的读者线程完成对该数据的读取。只有在<code>synchronize_rcu</code>返回之后，旧数据的内存才可以被安全地释放。</li>
<li><strong>实现类型安全的内存管理</strong>：在多线程环境下，写者线程在释放旧对象的内存时，需要确保不会有线程继续访问该对象。通过<code>synchronize_rcu</code>，写者线程可以等待所有的读操作结束，保证该内存块不再被引用，然后安全地释放内存。</li>
<li><strong>引用计数替代方案</strong>：传统的引用计数需要在每次引用时都对共享计数器进行原子操作，这在高并发情况下性能较差。而RCU提供了一种替代方案：只需确保在删除对象前所有引用操作都完成，无需每次修改计数器。<code>synchronize_rcu</code>就是这种场景下的核心机制，确保对象被安全释放。</li>
</ol>
<p>为了更好地理解<code>synchronize_rcu</code>的实际应用，以下是一个文件系统目录项缓存（<code>dentry</code>）的删除示例：</p>
<p>在Linux的虚拟文件系统（VFS）中，目录项（<code>dentry</code>）缓存是一个共享的数据结构，频繁用于文件路径解析。假设某个线程要删除一个目录项，具体步骤如下：</p>
<ol>
<li><strong>读取操作</strong>：读者线程通过<code>rcu_read_lock</code>进入读侧临界区，开始读取<code>dentry</code>结构的数据。在此过程中，它不会阻塞其他读者线程，也不受写者线程的影响。</li>
<li><strong>删除操作</strong>：写者线程想要删除一个目录项时，首先将该目录项从缓存中移除，但不会立即释放内存。接下来，它会调用<code>synchronize_rcu</code>。</li>
<li><strong>等待同步</strong>：<code>synchronize_rcu</code>会等待所有当前正在读取该目录项的读者线程完成读取操作。这是通过等待所有CPU上的上下文切换来实现的。</li>
<li><strong>释放内存</strong>：当<code>synchronize_rcu</code>返回时，表示所有读操作都已经完成。此时，写者线程可以安全地释放该目录项的内存。</li>
</ol>
<p>通过这样的设计，读者线程在访问共享数据时不需要加锁，从而避免了锁竞争和死锁的风险，提升了系统的并发性能。而写者线程则通过<code>synchronize_rcu</code>确保更新操作的安全性。</p>
<div class="table-wrapper"><table>
  <thead>
      <tr>
          <th style="text-align: center">优势</th>
          <th style="text-align: center">局限性</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center"><strong>高性能</strong>：<code>synchronize_rcu</code>的最大优势是它允许读操作完全无锁化，极大地提高了高并发场景下的读取性能。</td>
          <td style="text-align: center"><strong>写操作开销较高</strong>：虽然读操作几乎是无开销的，但写操作（特别是<code>synchronize_rcu</code>的调用）可能会带来较高的延迟，尤其是在高并发的系统中。</td>
      </tr>
      <tr>
          <td style="text-align: center"><strong>延迟友好</strong>：在实时系统中，<code>synchronize_rcu</code>的确定性完成时间有助于避免不可预测的长时间延迟。</td>
          <td style="text-align: center"><strong>实时性限制</strong>：虽然有快速同步版本（如<code>call_rcu</code>），但在某些对实时性要求极高的系统中，等待所有CPU的上下文切换可能仍然不足够快。</td>
      </tr>
      <tr>
          <td style="text-align: center"><strong>简单的同步模型</strong>：写者只需等待所有读者完成操作，而不需要直接和每个读者进行通信。</td>
          <td style="text-align: center">&hellip;</td>
      </tr>
  </tbody>
</table></div>
<p><code>synchronize_rcu</code>是Linux内核中一种强大的同步工具，它通过等待所有读者线程完成操作，确保共享数据在更新或删除时的安全性。尽管它引入了一定的写操作开销，但它极大地提升了并发读取场景中的性能。因此，RCU及其<code>synchronize_rcu</code>函数在诸如网络栈、文件系统和虚拟文件系统等读密集型子系统中得到了广泛的应用。</p>
<hr>
<h2 id="关于-synchronize_rcu-的深入探讨">关于 <code>synchronize_rcu</code> 的深入探讨
</h2><p>在Linux内核的RCU机制中，<code>synchronize_rcu</code> 是关键的一环，负责确保数据的安全更新。它的作用是在修改某个数据结构之前，等待所有现存的读取操作完成，以便写操作可以在不干扰正在进行的读操作的前提下进行。</p>
<p>当一个线程调用<code>rcu_read_lock</code>进入读侧临界区时，它被标记为正在读取一个RCU保护的数据结构。写者线程不能阻塞正在读取的线程，因此<code>rcu_read_lock</code>和<code>rcu_read_unlock</code>提供了一种轻量级的机制来避免锁竞争。</p>
<p>在需要修改或删除数据结构时，写者线程调用<code>synchronize_rcu</code>，该函数会等待所有活跃的RCU读侧临界区结束。只有当所有现有的读操作完成后，<code>synchronize_rcu</code>才会返回，这样可以确保没有读者再访问旧版本的数据结构。</p>
<p><code>synchronize_rcu</code> 通过等待内核中的每个CPU执行至少一次上下文切换来确认所有的RCU临界区都已经完成。这意味着当每个CPU完成一次任务切换时，所有当前的读侧临界区都会终止，确保任何线程不再访问旧数据。</p>
<p>在实现层面，Linux并没有直接创建额外的线程在每个CPU上运行（尽管一些初步的实现看起来像是在这样做），而是通过一种更优化的方式来检查上下文切换是否完成。这种方式显著减少了等待开销，而不需要额外的系统资源去处理CPU间的调度。</p>
<p>关于时间开销的问题是合理的：如果我们简单地让调用线程在每个CPU上运行一次，确实会产生较高的延迟。这个问题在早期的系统设计中显得尤为重要，特别是在高并发的系统中，涉及大量的CPU核心和繁忙的处理任务。</p>
<p>不过，<code>synchronize_rcu</code> 的实现已经针对这一问题进行了优化，它不需要在每个CPU上调度一个独立的线程来执行上下文切换。实际上，它利用了系统的调度器和现有的上下文切换事件来跟踪CPU的状态。通过监视调度器的状态变化，<code>synchronize_rcu</code> 可以检测到每个CPU是否已经完成了必要的上下文切换。因此，它在性能上有较大的提升，而不必实际等待每个CPU独立运行。</p>
<p>为了进一步减少延迟，Linux还提供了更快速的同步版本，称为<code>call_rcu</code>。<code>call_rcu</code> 是<code> synchronize_rcu</code>的异步版本，允许线程在不需要同步等待的情况下发起一个回调函数来释放内存。当所有的读者线程退出RCU临界区后，这个回调函数会被调用，完成最终的内存清理工作。</p>
<p>异步的<code>call_rcu</code>可以极大地减少线程的阻塞时间，尤其是在高并发的场景下。这对于内核中的许多时间敏感的子系统，例如网络栈和文件系统，都是至关重要的。</p>
<p><strong>一个实际例子：文件目录项（dentry）删除</strong></p>
<p>通过一个常见的例子来说明<code>synchronize_rcu</code>的实际应用：删除文件目录项（<code>dentry</code>）缓存。</p>
<ol>
<li><strong>读侧操作</strong>：假设某个线程正在通过<code>rcu_read_lock</code>进入读侧临界区，读取文件目录项的相关信息。读操作不会被阻塞，它继续无锁地访问共享数据。</li>
<li><strong>写侧操作</strong>：当需要删除一个<code>dentry</code>时，写者线程首先从目录缓存中移除该<code>dentry</code>，但不会立即释放它所占用的内存。为了确保安全，写者线程随后调用<code>synchronize_rcu</code>，等待所有并发的读者线程完成操作。</li>
<li><strong>等待同步</strong>：在<code>synchronize_rcu</code>的执行期间，系统将等待所有正在执行的读操作完成。这是通过上下文切换跟踪来实现的。它不会阻塞新读者的进入，只是确保在调用时已经存在的读者完成任务。</li>
<li><strong>安全释放内存</strong>：一旦<code>synchronize_rcu</code>返回，意味着没有线程还在访问被删除的<code>dentry</code>，此时系统可以安全地释放它所占用的内存。</li>
</ol>
<p><code>synchronize_rcu</code> 是Linux内核中处理并发更新操作的关键工具。尽管它需要等待系统中所有读者线程完成操作，但其设计通过上下文切换检测机制有效地避免了额外的系统开销。它在提升并发性能的同时，还为内核的许多子系统提供了稳定和确定的响应时间。对于高性能网络和文件系统等场景，它尤其具有显著的优势。</p>
<hr>
<h2 id="异步版本的-synchronize_rcu-call_rcu">异步版本的 <code>synchronize_rcu</code>: <code>call_rcu</code>
</h2><p><code>call_rcu</code> 是 Linux 内核 RCU 机制中用于延迟内存释放或资源清理的异步函数。与同步等待所有现有读操作完成的 <code>synchronize_rcu</code> 不同，<code>call_rcu</code> 会安排一个回调函数在所有 CPU 都完成至少一次上下文切换后执行。这种机制允许写者线程无需阻塞，继续执行其他操作，从而提高系统的并发性和性能。</p>
<p><code>call_rcu</code> 的函数原型如下：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">call_rcu</span><span class="p">(</span><span class="k">struct</span> <span class="n">rcu_head</span> <span class="o">*</span><span class="n">head</span><span class="p">,</span> <span class="kt">rcu_callback_t</span> <span class="n">func</span><span class="p">);</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li><code>struct rcu_head *head</code>：这是嵌入在要被释放或修改的对象中的 RCU 头结构，用于跟踪延迟操作。</li>
<li><code>rcu_callback_t func</code>：指定的回调函数，当所有 RCU 临界区完成后调用这个函数。通常，这个回调函数包含释放内存或清理资源的代码。</li>
</ul>
<p>在内核中，<code>call_rcu</code> 主要用于延迟资源回收，例如内存释放。以下是一个常见的使用场景，涉及删除数据结构中的对象：</p>
<ol>
<li><strong>读取数据（读侧临界区）</strong>：
多个读者线程可能会在 RCU 读侧临界区内访问数据结构，通过 <code>rcu_read_lock()</code> 和 <code>rcu_read_unlock()</code> 确保不会被中断。</li>
<li><strong>删除对象（写侧操作）</strong>：
当一个线程需要删除某个对象时，它会从数据结构中将该对象移除，但不立即释放内存。随后，调用 <code>call_rcu</code>，指定一个回调函数来在所有读者操作完成后释放内存。</li>
</ol>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">my_callback</span><span class="p">(</span><span class="k">struct</span> <span class="n">rcu_head</span> <span class="o">*</span><span class="n">head</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">my_data_t</span> <span class="o">*</span><span class="n">data</span> <span class="o">=</span> <span class="nf">container_of</span><span class="p">(</span><span class="n">head</span><span class="p">,</span> <span class="kt">my_data_t</span><span class="p">,</span> <span class="n">rcu</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="nf">free</span><span class="p">(</span><span class="n">data</span><span class="p">);</span>  <span class="c1">// 安全地释放内存
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">remove_data</span><span class="p">(</span><span class="kt">my_data_t</span> <span class="o">*</span><span class="n">data</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// 从数据结构中移除 data
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="nf">call_rcu</span><span class="p">(</span><span class="o">&amp;</span><span class="n">data</span><span class="o">-&gt;</span><span class="n">rcu</span><span class="p">,</span> <span class="n">my_callback</span><span class="p">);</span>  <span class="c1">// 异步安排内存清理
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ol start="3">
<li><strong>回调函数执行</strong>：
当所有 CPU 都完成至少一次上下文切换时，系统将调用 <code>my_callback</code>，安全地释放内存。</li>
</ol>
<p><code>call_rcu</code> <strong>的优点</strong></p>
<ol>
<li><strong>非阻塞执行</strong>：
相比于 <code>synchronize_rcu</code>，<code>call_rcu</code> 不会让调用线程等待，因此在高并发系统中能够更高效地进行资源管理。</li>
<li><strong>降低延迟</strong>：
对于实时或性能敏感的应用程序，<code>call_rcu</code> 的异步特性可以减少阻塞时间，避免长时间等待所有读者完成操作。</li>
<li><strong>批处理更新</strong>：
由于 <code>call_rcu</code> 是非阻塞的，可以同时处理大量更新。内核的 RCU 实现会将多个 <code>call_rcu</code> 的调用批量处理，从而减少上下文切换的开销。</li>
</ol>
<p><code>call_rcu</code> 通过每个 CPU 的数据结构维护回调列表。当所有 CPU 都完成至少一次上下文切换时，系统会调用这些回调函数，执行延迟的清理操作。其具体的工作流程为：</p>
<ol>
<li><strong>标记上下文切换</strong>：当调用 <code>call_rcu</code> 时，它不会立即执行回调，而是记录一个待处理的回调，并开始跟踪所有 CPU 的上下文切换。</li>
<li><strong>检测上下文切换</strong>：RCU 系统周期性检查每个 CPU 是否完成了至少一次上下文切换，这个过程经过优化，避免了不必要的性能开销。</li>
<li><strong>执行回调</strong>：当所有 CPU 都完成至少一次上下文切换时，系统会在安排的 CPU 上执行回调，进行内存释放或资源清理。</li>
</ol>
<p>在实践中，<code>call_rcu</code> 具有极高的可扩展性，可同时处理数千个回调请求。通过批量处理上下文切换的检测，系统大大降低了每次调用的开销。</p>
<p><code>call_rcu</code> 的一个重要应用案例是在 Linux 网络栈中。网络栈通常需要高吞吐量和低延迟，使用同步等待的方式效率不高。例如，在删除 IP 选项或更新路由表时，<code>call_rcu</code> 能够在所有读者完成后异步释放旧数据，从而避免了不必要的阻塞。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">udp_sendmsg</span><span class="p">(</span><span class="kt">sock_t</span> <span class="o">*</span><span class="n">sock</span><span class="p">,</span> <span class="kt">msg_t</span> <span class="o">*</span><span class="n">msg</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">ip_options_t</span> <span class="o">*</span><span class="n">opts</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="n">opts</span> <span class="o">=</span> <span class="nf">rcu_dereference</span><span class="p">(</span><span class="n">sock</span><span class="o">-&gt;</span><span class="n">opts</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">opts</span> <span class="o">!=</span> <span class="nb">NULL</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="c1">// 处理 IP 选项
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="nf">rcu_read_unlock</span><span class="p">();</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">setsockopt</span><span class="p">(</span><span class="kt">sock_t</span> <span class="o">*</span><span class="n">sock</span><span class="p">,</span> <span class="kt">int</span> <span class="n">opt</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">arg</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">opt</span> <span class="o">==</span> <span class="n">IP_OPTIONS</span><span class="p">)</span> <span class="p">{</span><span class="n">s</span>
</span></span><span class="line"><span class="cl">        <span class="kt">ip_options_t</span> <span class="o">*</span><span class="n">old</span> <span class="o">=</span> <span class="n">sock</span><span class="o">-&gt;</span><span class="n">opts</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="kt">ip_options_t</span> <span class="o">*</span><span class="n">new</span> <span class="o">=</span> <span class="n">arg</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">        <span class="nf">rcu_assign_pointer</span><span class="p">(</span><span class="n">sock</span><span class="o">-&gt;</span><span class="n">opts</span><span class="p">,</span> <span class="n">new</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">old</span> <span class="o">!=</span> <span class="nb">NULL</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="nf">call_rcu</span><span class="p">(</span><span class="o">&amp;</span><span class="n">old</span><span class="o">-&gt;</span><span class="n">rcu</span><span class="p">,</span> <span class="n">kfree_rcu</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>在此示例中，<code>call_rcu</code> 确保在释放旧的 IP 选项之前，所有可能使用这些选项的线程都已经完成操作。</p>
<p><code>call_rcu</code> 是一种延迟执行的异步机制，通过在所有 CPU 完成上下文切换后执行指定的回调函数，解决了高并发场景下的内存释放和资源管理问题。相比于 <code>synchronize_rcu</code>，它具有显著的性能优势和延迟优化，特别适用于网络栈、文件系统等读操作占优的高性能系统。</p>
<hr>
<h2 id="linux-nmi">Linux NMI
</h2><p>Linux 的 <strong>NMI (Non-Maskable Interrupt)</strong> 系统是处理一种高优先级硬件中断的机制，这种中断无法被屏蔽或忽略。NMI 通常用于非常关键的任务，比如检测系统错误、硬件问题或执行高精度的性能监控。它的优先级高于普通中断，在某些情况下，即使系统中断被禁用或屏蔽，NMI 依然会被处理。其主要应用有如下几点：</p>
<ol>
<li><strong>硬件错误检测</strong>：NMI 被广泛用于报告严重的硬件错误，比如内存纠错（ECC）错误、CPU 错误或其他硬件问题。当硬件检测到这些严重的错误时，它会触发 NMI，系统会立即进入 NMI 处理程序，快速响应这些错误。</li>
<li><strong>性能监控</strong>：NMI 系统常用于高精度的性能监控工具，如 <code>perf</code> 或 <code>OProfile</code>，这些工具依赖 NMI 来收集系统性能数据。通过 NMI，这些工具能够定期中断 CPU，获取系统状态和性能计数器的精确信息。</li>
<li><strong>看门狗定时器</strong>：NMI 还常用于看门狗定时器，当系统进入死锁或长时间无响应时，看门狗定时器会触发 NMI 来执行系统恢复操作，防止系统完全崩溃。</li>
</ol>
<p>在 NMI 系统中，Linux 内核通常会结合 <strong>RCU (Read-Copy-Update)</strong> 机制来处理并发访问的同步问题，尤其是 NMI 处理程序的动态注册和注销。由于 NMI 具有非常高的优先级，并且可以在任何时间打断系统操作，传统的锁机制在此场景中可能会引发死锁或性能问题。因此，RCU 提供了一种无锁机制来管理 NMI 处理程序列表。RCU 在 NMI 系统中的具体作用：</p>
<ol>
<li><strong>动态注册和注销 NMI 处理程序</strong>：在 NMI 系统中，处理程序可能会根据需要动态注册和注销。在注销处理程序时，需要确保没有 CPU 正在执行该处理程序。通过 RCU，可以在注销 NMI 处理程序后调用 <code>synchronize_rcu</code> 来等待所有 NMI 处理操作完成，确保不会有 CPU 再次访问已被删除的处理程序。</li>
<li><strong>高并发性能</strong>：RCU 提供了一种无锁机制，允许多个 CPU 高效访问 NMI 处理程序列表。这对于依赖频繁调用 NMI 的应用（如性能监控工具）至关重要，可以避免因频繁的锁竞争而导致的性能瓶颈。</li>
<li><strong>确定性的执行时间</strong>：在高优先级的 NMI 系统中，使用 RCU 机制可以保证进入和退出 NMI 处理程序的执行时间是确定的，这对于实时系统尤为关键。相比于读写锁等阻塞同步机制，RCU 能避免不确定的执行时间问题。</li>
</ol>
<p>以下是一个使用 RCU 进行 NMI 处理程序注册和注销的简化代码示例：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="kt">rcu_list_t</span> <span class="n">nmi_list</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="kt">spinlock_t</span> <span class="n">nmi_list_lock</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">handle_nmi</span><span class="p">()</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="nf">rcu_read_lock</span><span class="p">();</span>  <span class="c1">// 进入 RCU 临界区
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="nf">rcu_list_for_each</span><span class="p">(</span><span class="o">&amp;</span><span class="n">nmi_list</span><span class="p">,</span> <span class="kt">handler_t</span> <span class="n">cb</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nf">cb</span><span class="p">();</span>  <span class="c1">// 调用每个 NMI 处理程序
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="nf">rcu_read_unlock</span><span class="p">();</span>  <span class="c1">// 退出 RCU 临界区
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">register_nmi_handler</span><span class="p">(</span><span class="kt">handler_t</span> <span class="n">cb</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="nf">spin_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">nmi_list_lock</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="nf">rcu_list_add</span><span class="p">(</span><span class="o">&amp;</span><span class="n">nmi_list</span><span class="p">,</span> <span class="n">cb</span><span class="p">);</span>  <span class="c1">// 注册新的 NMI 处理程序
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="nf">spin_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">nmi_list_lock</span><span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">unregister_nmi_handler</span><span class="p">(</span><span class="kt">handler_t</span> <span class="n">cb</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="nf">spin_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">nmi_list_lock</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="nf">rcu_list_remove</span><span class="p">(</span><span class="o">&amp;</span><span class="n">nmi_list</span><span class="p">,</span> <span class="n">cb</span><span class="p">);</span>  <span class="c1">// 从列表中移除处理程序
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="nf">spin_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">nmi_list_lock</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="nf">synchronize_rcu</span><span class="p">();</span>  <span class="c1">// 等待所有 NMI 操作完成
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>通过上面的代码，NMI 处理程序的注册和注销可以在高并发的环境下安全进行。<code>synchronize_rcu</code> 用于确保注销处理程序时，所有正在执行的 NMI 操作已经结束，防止无效指针访问导致的系统崩溃。</p>
<p>Linux NMI 系统是用于处理高优先级硬件中断的关键机制，通常用于检测硬件故障、执行高精度性能监控以及管理看门狗定时器。结合 RCU 机制，NMI 系统能够实现动态的处理程序管理，并提高系统的并发性能和可靠性。</p>
<hr>
<h2 id="传统锁与-rcu">传统锁与 RCU
</h2><p>在多线程或多处理器系统中，如何有效地同步共享数据的访问是一个关键问题。传统的锁机制和 RCU（Read-Copy-Update）是两种广泛使用的同步机制。以下是对比这两种同步方法的详细分析。</p>
<p>传统锁的核心原理是通过<strong>互斥锁</strong>来确保只有一个线程可以访问某个共享资源，而其他线程必须等待，直到该资源被释放。这种方式包括多种类型的锁，比如<strong>互斥锁</strong>（mutex）、<strong>读写锁</strong>（read-write lock）等。</p>
<ul>
<li><strong>互斥锁（Mutex）</strong>：互斥锁确保同一时刻只有一个线程能够访问共享数据。它会阻塞其他试图访问相同资源的线程，直到锁被释放。</li>
<li><strong>读写锁（Read-Write Lock）</strong>：允许多个读者线程并发访问资源，但写者线程必须独占该资源。读者之间不会相互阻塞，但写者和其他读者之间互斥。</li>
</ul>
<div class="table-wrapper"><table>
  <thead>
      <tr>
          <th style="text-align: center">传统锁优点</th>
          <th style="text-align: center">传统锁缺点</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center"><strong>简单直观</strong>：传统锁的使用方法非常简单明确，只需要在进入临界区前加锁，退出时解锁即可。</td>
          <td style="text-align: center"><strong>性能瓶颈</strong>：传统锁的一个主要问题是它可能导致性能瓶颈，尤其是在高并发读操作的场景中。读者线程和写者线程之间的互斥可能导致大量等待，进而拖慢整个系统的性能。</td>
      </tr>
      <tr>
          <td style="text-align: center"><strong>对写密集型操作有优势</strong>：传统锁对于写操作频繁的场景非常有效，因为它通过强制序列化写操作来确保数据一致性。</td>
          <td style="text-align: center"><strong>死锁风险</strong>：不正确的锁顺序或嵌套锁的使用可能导致死锁问题，即多个线程彼此等待锁释放，从而永久阻塞。</td>
      </tr>
  </tbody>
</table></div>
<p>RCU 是 Linux 内核中一种非常高效的同步机制，专为<strong>读多写少</strong>的场景设计。它通过允许读者线程和写者线程同时访问共享资源，而不会彼此阻塞，从而极大地提高了并发性。</p>
<p>RCU 的基本原理是<strong>读者线程不需要锁</strong>来访问数据，而写者线程在更新数据时，会首先创建数据的副本，然后通过同步机制（如 <code>synchronize_rcu</code> 或 <code>call_rcu</code>）来确保所有当前正在读取该数据的线程完成后，才会删除或释放旧数据。</p>
<div class="table-wrapper"><table>
  <thead>
      <tr>
          <th style="text-align: center">RCU优点</th>
          <th style="text-align: center">RCU缺点</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center"><strong>高并发性</strong>：RCU 允许读者线程无锁访问数据，因此在大量读操作场景下，RCU 提供了极高的并发性。多个读者线程可以同时读取数据，而不会发生互相等待。</td>
          <td style="text-align: center"><strong>写操作的复杂性</strong>：虽然 RCU 在读操作上效率极高，但写操作需要复杂的同步机制，如 <code>synchronize_rcu</code> 来确保所有读者线程完成后再进行更新。这意味着在写密集型场景中，RCU 的性能可能并不优于传统锁。</td>
      </tr>
      <tr>
          <td style="text-align: center"><strong>低开销</strong>：RCU 不涉及复杂的锁操作，避免了传统锁中因加锁和解锁带来的性能开销。</td>
          <td style="text-align: center"><strong>内存消耗</strong>：RCU 的设计要求在更新数据时创建数据副本，因此在高频率更新的场景下，可能会导致内存使用量增加。</td>
      </tr>
      <tr>
          <td style="text-align: center"><strong>确定性时间</strong>：RCU 中的读操作具有确定性时间，不会像传统锁那样因锁争用而导致不确定的等待时间。</td>
          <td style="text-align: center">&hellip;</td>
      </tr>
  </tbody>
</table></div>
<p>RCU 和传统锁在多核系统上的性能差异较为明显，尤其是在读操作占多数的场景下。</p>
<p><strong>读写锁 vs RCU</strong></p>
<div class="table-wrapper"><table>
  <thead>
      <tr>
          <th></th>
          <th style="text-align: center">读写锁</th>
          <th style="text-align: center">RCU</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td>读操作</td>
          <td style="text-align: center">使用传统的读写锁来保护同样的读操作，在同样的系统中，获取和释放读锁的开销为 89 纳秒。当 CPU 核心数量增加时，读写锁的开销显著增加。在 16 核心的系统上，获取和释放读锁的时间增至 6654 纳秒。</td>
          <td style="text-align: center">RCU 的读操作不需要任何锁机制，因此非常快速。在一个典型的多核系统中，进入和退出 RCU 临界区（调用 <code>rcu_read_lock</code> 和 <code>rcu_read_unlock</code>）的开销大约是 6 纳秒，无论系统中有多少 CPU 核心，RCU 的读操作开销基本保持不变。</td>
      </tr>
      <tr>
          <td>并发性</td>
          <td style="text-align: center">读写锁会在多个读者竞争锁时导致缓存失效，降低并发性能。</td>
          <td style="text-align: center">RCU 的并发读操作不会相互影响，读者线程之间不需要等待。</td>
      </tr>
      <tr>
          <td>死锁风险</td>
          <td style="text-align: center">传统锁，特别是嵌套锁和多个锁的场景中，容易导致死锁。例如，如果一个线程获取了一个锁后被中断，而另一个线程同时尝试获取相同的锁，那么死锁可能发生。</td>
          <td style="text-align: center">RCU 由于其无锁的读操作，不存在读者线程之间的锁竞争，也不会出现读者线程和写者线程之间的死锁问题。只有在某些特殊情况下，写者线程可能会因为等待 RCU 临界区的完成而阻塞，但这不会导致传统意义上的死锁。</td>
      </tr>
  </tbody>
</table></div>
<p>RCU 和传统锁的应用场景有所不同。</p>
<div class="table-wrapper"><table>
  <thead>
      <tr>
          <th style="text-align: center">适合使用传统锁的场景</th>
          <th style="text-align: center">适合使用 RCU 的场景</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center"><strong>写操作占主导</strong>：在写操作频繁的场景下，传统锁机制更加适合，因为它能够通过强制互斥确保数据的一致性，避免复杂的同步机制。</td>
          <td style="text-align: center"><strong>读操作占主导</strong>：RCU 特别适合读操作占多数的场景，尤其是内核中的文件系统、网络栈等场景。在这些场景中，读者线程不需要等待其他读者或写者，系统能够提供极高的并发性能。</td>
      </tr>
      <tr>
          <td style="text-align: center"><strong>实时系统的精确控制</strong>：在某些实时系统中，需要严格的顺序保证，并且必须确保某些操作独占资源。在这种场景下，传统锁可能提供更好的控制。</td>
          <td style="text-align: center"><strong>高并发性和低延迟</strong>：对于对并发性和低延迟有较高要求的系统，RCU 是理想的选择。由于其读操作几乎无阻塞，因此可以减少延迟，提升系统的整体响应速度。</td>
      </tr>
  </tbody>
</table></div>
<p>传统锁和 RCU 各有其优缺点，适合不同的应用场景。传统锁提供了简单、可靠的互斥访问方式，适用于写操作频繁的场景，但在高并发读操作下性能表现不佳。相比之下，RCU 是一种高效的并发同步机制，能够在读密集型场景中大幅提高性能，但它在写操作频繁的场景中表现稍弱。</p>
<blockquote>
<p>RCU 替代读写锁的典型场景</p>
<p>Linux 内核中的 <strong>PID 哈希表</strong> 就是使用 RCU 替代读写锁的一个典型例子。PID 哈希表用于将进程标识符（PID）映射到进程信息。在这个例子中，读取者通过调用 <code>rcu_read_lock</code> 来获取进程信息，读取完成后调用 <code>rcu_read_unlock</code> 释放锁。而写者线程通过自旋锁来同步写操作。</p>
<p>以下是一个简化的代码示例：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="kt">process_t</span> <span class="o">*</span><span class="nf">pid_lookup</span><span class="p">(</span><span class="kt">int</span> <span class="n">pid</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">process_t</span> <span class="o">*</span><span class="n">p</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="nf">rcu_read_lock</span><span class="p">();</span>  <span class="c1">// 进入 RCU 临界区
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">p</span> <span class="o">=</span> <span class="n">pid_table</span><span class="p">[</span><span class="nf">pid_hash</span><span class="p">(</span><span class="n">pid</span><span class="p">)].</span><span class="n">process</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="n">p</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nf">atomic_inc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">p</span><span class="o">-&gt;</span><span class="n">ref</span><span class="p">);</span>  <span class="c1">// 增加引用计数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    
</span></span><span class="line"><span class="cl">    <span class="nf">rcu_read_unlock</span><span class="p">();</span>  <span class="c1">// 退出 RCU 临界区
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">return</span> <span class="n">p</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">pid_remove</span><span class="p">(</span><span class="kt">int</span> <span class="n">pid</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">process_t</span> <span class="o">**</span><span class="n">p</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="nf">spin_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">pid_table</span><span class="p">[</span><span class="nf">pid_hash</span><span class="p">(</span><span class="n">pid</span><span class="p">)].</span><span class="n">lock</span><span class="p">);</span>  <span class="c1">// 使用自旋锁同步写操作
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="n">p</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">pid_table</span><span class="p">[</span><span class="nf">pid_hash</span><span class="p">(</span><span class="n">pid</span><span class="p">)].</span><span class="n">process</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="nf">rcu_assign_pointer</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span>  <span class="c1">// 安全发布 NULL
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="nf">spin_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">pid_table</span><span class="p">[</span><span class="nf">pid_hash</span><span class="p">(</span><span class="n">pid</span><span class="p">)].</span><span class="n">lock</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="o">*</span><span class="n">p</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="nf">call_rcu</span><span class="p">(</span><span class="n">pid_free</span><span class="p">,</span> <span class="o">*</span><span class="n">p</span><span class="p">);</span>  <span class="c1">// 使用 RCU 异步释放旧数据
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>在这个例子中，RCU 的读操作是并发的，且不需要阻塞写操作。写操作通过自旋锁保护，并在合适的时间点调用 <code>call_rcu</code> 异步释放旧数据。</p>
</blockquote>
<hr>
<h2 id="linux-的-slab-分配器">Linux 的 slab 分配器
</h2><p>Linux 的 slab 分配器是一种内存管理机制，用于高效地管理和分配内核中频繁使用的小对象内存。它通过将一块大的内存页面分割成多个相同大小的对象，并维护对象的生命周期，以便快速分配和释放内存。与常规的动态内存分配器相比，slab 分配器有以下几个特点：</p>
<ol>
<li><strong>高效性</strong>：slab 分配器通过减少内存碎片和频繁的内存分配开销来提高性能，特别是在需要频繁创建和销毁对象的场景中。</li>
<li><strong>类型安全</strong>：slab 分配器为每种类型的对象创建特定的内存缓存区，每个缓存区中包含相同类型和大小的对象。因此，这些对象的内存分配和释放在类型上是安全的，避免了对象混淆。</li>
<li><strong>缓存复用</strong>：对象在释放后，slab 不会立即将其内存返回给系统，而是将该对象保留在缓存中，供下次分配时复用。这样可以避免频繁的内存分配和释放操作。</li>
</ol>
<hr>
<h2 id="类型安全">类型安全
</h2><p>在 slab 分配器中，开发者可以设置一个特殊的 <code>SLAB_DESTROY_BY_RCU</code> 标志，这个标志会确保在 RCU 同步完成之前，不会将内存重新分配给不同类型的对象。如果使用 <code>SLAB_DESTROY_BY_RCU</code> 标志，意味着对象的内存不会在 RCU 同步完成之前被销毁或重新分配。这就实现了“类型安全内存”的效果。举个例子：</p>
<ul>
<li><strong>内存分配</strong>：当内核使用 slab 分配器分配对象时，slab 会从一个页面（page）中分割出相同类型的对象，并在该页面中分配所需的内存。</li>
<li><strong>内存回收</strong>：当一个页面中的所有对象都被释放后，该页面可以返回给系统。如果设置了 <code>SLAB_DESTROY_BY_RCU</code> 标志，那么在释放这些对象之前，RCU 会确保没有线程仍然在访问这些对象的内存。</li>
<li><strong>类型安全</strong>：在这种方式下，即使某个线程在 RCU 临界区内仍然引用了一个对象，系统也能确保在对象的内存被重新分配给另一个对象类型之前完成同步，避免了类型混乱的问题。</li>
</ul>
<p>反向页表是一个典型的使用类型安全内存的例子。反向页表用于管理物理页和虚拟地址之间的映射。在 Linux 内核中，每个物理页通过 <code>page_t</code> 表示，虚拟地址映射则通过 <code>anon_vma_t</code> 来管理。为了防止在线程引用的 <code>anon_vma_t</code> 被释放时重新分配给其他类型的对象，内核可以通过 RCU 机制实现类型安全的内存分配。具体来说：</p>
<ul>
<li>当一个物理页被解映射时，<code>anon_vma_t</code> 对象可能会被释放，但 RCU 确保在释放之前，所有引用该对象的线程已经完成了其操作。</li>
<li>如果某个线程仍然在读取 <code>anon_vma_t</code>，它可以通过检测对象的状态来避免访问无效的内存。</li>
</ul>
<hr>
<h2 id="类型安全内存的防护传统方式与rcu机制的比较">类型安全内存的防护：传统方式与RCU机制的比较
</h2><p>在多线程或多处理器系统中，内存管理和对象生命周期管理是非常复杂的任务。尤其是在对象释放过程中，如果某个对象被多个线程共享访问，那么在某个线程释放该对象内存的同时，其他线程可能仍然在使用该对象，这就会导致<strong>悬空指针（dangling pointer）<strong>和</strong>类型安全问题</strong>。为了解决这些问题，系统在没有 RCU 机制的情况下，通常采用传统的防护方式来实现类型安全内存，而引入 RCU 之后，内存管理的复杂性和性能问题得到了很大程度的简化。</p>
<p>在没有 RCU 机制时，内核通常使用以下几种方法来确保类型安全内存：</p>
<ol>
<li><strong>引用计数（Reference Counting）</strong>：
<ul>
<li><strong>工作机制</strong>：通过在对象结构中维护一个引用计数器，来跟踪当前对象被多少个线程引用。每当一个线程开始使用对象时，引用计数加 1，当线程停止使用时，引用计数减 1。只有当引用计数降至 0 时，才能安全地释放该对象的内存。</li>
<li><strong>防护方式</strong>：通过引用计数，系统能够确保在所有线程都不再引用该对象时，才释放内存，避免了悬空指针的问题。这种机制可以有效防止某个线程访问已释放对象的问题。</li>
<li><strong>缺点</strong>：引用计数的更新需要原子操作（如 <code>atomic_inc</code> 和 <code>atomic_dec</code>），在高并发的场景中，频繁的计数器更新会带来性能瓶颈。此外，在某些情况下（如循环引用），引用计数机制可能会失效，导致内存无法及时释放。</li>
</ul>
</li>
<li><strong>互斥锁（Mutex）和自旋锁（Spinlock）</strong>：
<ul>
<li><strong>工作机制</strong>：使用锁机制来保护共享对象的访问。在访问或修改对象前，线程必须先获取锁，操作完成后释放锁。这样可以防止多个线程同时访问对象导致数据不一致或非法内存访问。</li>
<li><strong>防护方式</strong>：锁机制可以确保在访问和释放对象时，不会有其他线程正在使用该对象，从而避免内存重用时出现类型不匹配的问题。</li>
<li><strong>缺点</strong>：锁机制容易导致性能问题，特别是在高并发场景下，频繁的加锁和解锁会带来显著的性能开销。此外，锁的使用不当可能引发死锁和优先级反转等问题。</li>
</ul>
</li>
<li><strong>延迟释放（Deferred Freeing）</strong>：
<ul>
<li><strong>工作机制</strong>：在对象释放时，使用某种机制延迟内存的真正释放，直到确定没有线程仍在访问该对象。例如，通过设置标志位或使用线程等待等方式，确保内存释放的安全性。</li>
<li><strong>防护方式</strong>：延迟释放可以防止悬空指针，但需要额外的同步操作和检测机制来判断对象是否可以安全释放，这增加了系统的复杂性。</li>
<li><strong>缺点</strong>：延迟释放机制可能导致内存占用增多，如果管理不当，甚至会导致内存泄漏。</li>
</ul>
</li>
</ol>
<p>RCU（Read-Copy-Update）是一种高效的同步机制，可以大大简化类型安全内存管理中的问题。RCU 的核心思想是允许读者线程在无锁的情况下访问数据，同时写者线程可以异步地进行数据更新，并在合适的时机释放旧数据。这种机制极大地降低了传统方式中同步操作的复杂性和性能开销。</p>
<ol>
<li><strong>RCU 的类型安全内存防护机制</strong>
<ul>
<li><strong>类型安全内存</strong>指的是当对象被释放后，其内存不会立即被重用为其他类型的对象，这样可以防止访问到已释放对象的线程遇到类型不匹配的问题。</li>
<li>在 RCU 中，为了实现类型安全内存，通常会结合**<code>SLAB_DESTROY_BY_RCU</code> 标志**来使用 slab 分配器（内核中一种高效的内存分配器）。这个标志会确保对象在 RCU 同步完成之前，其内存不会被重新分配为不同类型的对象。</li>
<li>在实际应用中，RCU 通过以下方式实现类型安全内存：
<ul>
<li>读者线程在 <code>rcu_read_lock</code> 和 <code>rcu_read_unlock</code> 之间无锁地访问对象，写者线程在更新或删除对象时，会调用 <code>call_rcu</code> 或 <code>synchronize_rcu</code> 来等待所有读操作完成，然后安全地释放内存。</li>
<li>在使用 <code>SLAB_DESTROY_BY_RCU</code> 标志时，内存分配器会确保对象内存在 RCU 临界区完成之前，不会被其他类型的对象重用。</li>
</ul>
</li>
</ul>
</li>
<li><strong>RCU 机制的优势</strong>
<ul>
<li><strong>高效性</strong>：RCU 的读操作几乎无锁，避免了传统锁机制中因加锁解锁带来的性能损失。在高并发读操作场景中，RCU 提供了极高的并发性和低延迟。</li>
<li><strong>低内存开销</strong>：RCU 的类型安全内存管理通过 <code>SLAB_DESTROY_BY_RCU</code> 的延迟释放机制，避免了引用计数器和锁带来的额外内存开销。</li>
<li><strong>避免死锁</strong>：RCU 的读操作和写操作分离机制有效地避免了传统锁机制中可能发生的死锁问题。</li>
</ul>
</li>
</ol>
<p>以下是一个简化的内核中 <code>RCU</code> 和 <code>引用计数</code> 两种类型安全内存防护方式的比较：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="c1">// 引用计数方式实现类型安全内存
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">struct</span> <span class="n">my_object</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">atomic_t</span> <span class="n">refcount</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// 数据字段
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">};</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">acquire_object</span><span class="p">(</span><span class="k">struct</span> <span class="n">my_object</span> <span class="o">*</span><span class="n">obj</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="nf">atomic_inc</span><span class="p">(</span><span class="o">&amp;</span><span class="n">obj</span><span class="o">-&gt;</span><span class="n">refcount</span><span class="p">);</span>  <span class="c1">// 增加引用计数
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">release_object</span><span class="p">(</span><span class="k">struct</span> <span class="n">my_object</span> <span class="o">*</span><span class="n">obj</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="p">(</span><span class="nf">atomic_dec_and_test</span><span class="p">(</span><span class="o">&amp;</span><span class="n">obj</span><span class="o">-&gt;</span><span class="n">refcount</span><span class="p">))</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">        <span class="nf">free</span><span class="p">(</span><span class="n">obj</span><span class="p">);</span>  <span class="c1">// 当引用计数为 0 时，释放对象
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">// RCU 方式实现类型安全内存
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">struct</span> <span class="n">my_rcu_object</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">struct</span> <span class="n">rcu_head</span> <span class="n">rcu</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="c1">// 数据字段
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">};</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">free_rcu_object</span><span class="p">(</span><span class="k">struct</span> <span class="n">rcu_head</span> <span class="o">*</span><span class="n">head</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="k">struct</span> <span class="n">my_rcu_object</span> <span class="o">*</span><span class="n">obj</span> <span class="o">=</span> <span class="nf">container_of</span><span class="p">(</span><span class="n">head</span><span class="p">,</span> <span class="k">struct</span> <span class="n">my_rcu_object</span><span class="p">,</span> <span class="n">rcu</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="nf">free</span><span class="p">(</span><span class="n">obj</span><span class="p">);</span>  <span class="c1">// 释放对象
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">release_rcu_object</span><span class="p">(</span><span class="k">struct</span> <span class="n">my_rcu_object</span> <span class="o">*</span><span class="n">obj</span><span class="p">)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="nf">call_rcu</span><span class="p">(</span><span class="o">&amp;</span><span class="n">obj</span><span class="o">-&gt;</span><span class="n">rcu</span><span class="p">,</span> <span class="n">free_rcu_object</span><span class="p">);</span>  <span class="c1">// 安排异步释放
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><ul>
<li>在传统引用计数方式中，每次对象的引用和释放都需要更新引用计数，这在高并发环境中可能带来性能瓶颈。</li>
<li>而在 RCU 方式中，<code>call_rcu</code> 可以异步地释放对象，在释放前无需同步等待所有引用完成，避免了频繁的锁操作，提高了系统性能。</li>
</ul>
<p>总的来说</p>
<ul>
<li><strong>没有 RCU 时</strong>：传统的类型安全内存防护主要依赖于引用计数和锁机制。这些方法能够确保在释放对象前，所有引用该对象的线程已经完成访问，从而避免悬空指针和类型安全问题。然而，这种方式在高并发环境中容易带来性能瓶颈和复杂的死锁问题。</li>
<li><strong>引入 RCU 之后</strong>：RCU 提供了更高效的类型安全内存防护机制。通过 RCU 的异步释放机制，可以在不阻塞读者线程的情况下安全释放对象，并结合 slab 分配器的 <code>SLAB_DESTROY_BY_RCU</code> 标志，确保内存不会被重新分配给不同类型的对象。这种机制在内核中得到了广泛的应用，特别是在文件系统和网络栈等高并发读操作的场景中。</li>
</ul>
<p>RCU 的引入显著提升了内核的性能和并发性，简化了类型安全内存管理的复杂性，并减少了传统锁机制带来的问题。</p>
<hr>
<h2 id="reverse-mapping">reverse-mapping
</h2><p>在Linux内核的虚拟内存管理中，**反向映射（Reverse Mapping）**是一个重要机制，用于管理物理内存页与虚拟地址空间之间的映射关系。具体来说，反向映射允许系统通过物理页找到哪些进程正在引用该页以及对应的虚拟地址是什么。</p>
<p>反向映射的基本功能：</p>
<ol>
<li><strong>通过物理页找到虚拟地址</strong>：传统的映射是从虚拟地址空间查找对应的物理页，但反向映射的目的是反过来，通过物理页找到所有引用该物理页的虚拟地址。这对于一些内存管理操作非常关键，特别是在共享内存页或分页回收时。</li>
<li><strong>多进程共享页的管理</strong>：在现代操作系统中，多个进程可以共享相同的物理页，比如当多个进程使用同一段共享内存或代码段时。反向映射帮助内核追踪这些共享情况，确保在回收或修改页时，可以正确处理所有共享关系。</li>
</ol>
<p>反向映射的具体用途：</p>
<ol>
<li><strong>分页回收</strong>：当内存不足时，操作系统会将不常使用的页交换到磁盘上。这时，内核需要知道哪些页可以被安全回收，以及哪些进程的页表需要更新。反向映射使内核能够通过物理页找到对应的虚拟地址，并确保在回收物理页时正确更新相应进程的页表。</li>
<li><strong>内存管理优化</strong>：反向映射还能帮助优化内存回收策略。通过了解哪些物理页被多个进程共享，内核可以避免不必要的交换操作（即不轻易将共享频繁的页回收），从而提高系统性能。</li>
<li><strong>页表更新</strong>：当物理页的内容发生变化或需要被换出到磁盘时，反向映射允许内核找到所有引用该页的虚拟地址，以便相应地更新这些进程的页表。</li>
</ol>
<p>在Linux内核中，反向映射的实现依赖于<strong>page structure</strong>和<strong>anon_vma</strong>等数据结构：</p>
<ol>
<li><code>page structure</code>每个物理页对应一个<code>page</code>结构体，其中包含了有关该页的信息，包括哪些进程引用了该页。<code>page</code> 是内核为每个物理内存页维护的数据结构。每个物理页都对应一个 <code>page</code> 结构，其中包含了关于该页的元数据，包括该页的状态、引用计数以及通过反向映射找到引用该页的进程。</li>
<li><code>anon_vma</code>匿名映射（比如进程的堆或栈）使用<code>anon_vma</code>来追踪虚拟内存区域。通过<code>anon_vma</code>，系统可以追踪到所有引用该物理页的虚拟地址。在匿名内存映射（例如进程的堆和栈）中，<code>anon_vma</code> 结构用来管理虚拟内存区域。它包含了一个链表，链表中的每一项都对应一个 <code>vm_area_struct</code>，这些结构用于表示该匿名页映射的进程及其虚拟地址范围。通过 <code>anon_vma</code>，内核能够从一个物理页找到所有引用该页的虚拟地址。</li>
</ol>
<p>当需要通过一个物理页找到它对应的虚拟地址时，反向映射机制的工作流程如下：</p>
<ul>
<li>首先，内核通过 <code>page</code> 结构找到所有引用该页的 <code>anon_vma</code> 结构。</li>
<li>然后，遍历 <code>anon_vma</code> 中的链表，获取所有引用该物理页的 <code>vm_area_struct</code> 结构。</li>
<li>最后，<code>vm_area_struct</code> 中包含了该物理页对应的虚拟地址范围，内核可以根据这些信息对所有引用该物理页的虚拟内存地址进行操作。</li>
</ul>
<p>反向映射在提高内存管理效率的同时也引入了一些开销。因为内核需要维护额外的数据结构来记录每个物理页与虚拟地址空间的关系，所以需要一定的内存开销。此外，在多进程大量共享内存的情况下，反向映射的管理会增加系统复杂度。为了优化反向映射，Linux 内核引入了多种优化技术，例如：</p>
<ul>
<li><strong>多级映射</strong>：通过分层次的映射结构减少对所有进程的遍历时间。</li>
<li><strong>延迟更新</strong>：当一个物理页的虚拟地址映射发生改变时，内核可以选择延迟更新页表，这样可以减少频繁的页表更新带来的性能开销。</li>
</ul>
<p>总的来说，反向映射的主要作用是在物理内存和虚拟内存之间提供一个高效的查询机制，特别是在需要从物理页追溯到对应的虚拟地址时。它在内存回收、页表更新和内存共享管理等方面起着重要作用。在现代操作系统中，反向映射是内存管理不可或缺的一部分，能够提升系统的整体性能并确保内存操作的正确性。</p>
<hr>
<h2 id="内存回收memory-reclamation">内存回收（Memory Reclamation）
</h2><p>在操作系统中，内存回收是一个非常重要的机制，用于在系统内存资源紧张时释放不再需要的内存。4.5 章节重点讨论了**页面回收（page reclaim）**的机制，以及如何通过反向映射来辅助高效的内存回收。</p>
<p>页面回收是操作系统的一种内存管理机制，当系统内存资源紧张时，操作系统会通过扫描内存，找到那些不再需要频繁访问的页面（如被交换到磁盘的页面或不活跃的页面）并将它们回收以释放物理内存。回收的页面可能会被重新分配给其他进程或操作系统使用。</p>
<p>内存回收机制主要包括以下几类操作：</p>
<ul>
<li><strong>交换（Swap）</strong>：将不活跃的页面写入磁盘，以释放物理内存。</li>
<li><strong>页面缓存回收</strong>：回收不再需要的缓存页面，例如文件系统缓存页面。</li>
<li><strong>匿名页回收</strong>：回收匿名内存页（如进程的堆和栈）中的不活跃页面。</li>
</ul>
<p>反向映射对于页面回收至关重要。当内核决定回收一个物理页时，它需要通过反向映射找到所有引用该页的进程，并更新这些进程的页表。这是确保页面回收不会破坏系统的一致性和正确性的重要步骤。</p>
<p>具体而言，当系统决定回收一个物理页时，反向映射提供了以下关键信息：</p>
<ul>
<li><strong>哪些进程引用了该页</strong>：反向映射帮助内核找到所有使用该物理页的进程。</li>
<li><strong>该页在进程中的虚拟地址</strong>：通过虚拟地址，内核能够更新页表，确保这些进程不会继续访问已回收的页面。</li>
</ul>
<p>Linux 内核中的内存回收策略依赖于多种因素，包括页面的访问频率、共享情况和物理内存的使用情况。主要的内存回收策略包括：</p>
<ul>
<li><strong>LRU（Least Recently Used）算法</strong>：内核使用 LRU 算法来判断哪些页面最不常使用，并优先回收这些页面。LRU 算法会将不常使用的页面移动到内存回收列表的尾部，以便被优先回收。</li>
<li><strong>优先回收共享少的页面</strong>：通过反向映射，内核能够找到那些被少数进程共享的页面。这些页面通常更容易被回收，因为它们的影响面较小。</li>
<li><strong>Swap 优化</strong>：当内存非常紧张时，内核可能需要将一些页面交换到磁盘上。反向映射机制在这时能够提供有用的信息，以确保被交换的页面不会在短时间内被频繁访问，从而减少交换操作的开销。</li>
</ul>
<p>在内存回收中，一个主要的挑战是确保系统性能不受太大影响。频繁的页面回收和页表更新操作可能导致系统性能下降，尤其是在多进程共享大量内存的场景中。因此，内核引入了多种优化措施，以确保内存回收过程的高效性：</p>
<ul>
<li><strong>批量回收</strong>：内核可以通过批量回收多个不活跃的页面，减少每次回收的开销。</li>
<li><strong>异步回收</strong>：为了减少对应用程序的影响，内存回收通常以异步方式进行。内核会在后台逐步回收内存，而不会阻塞正在执行的用户进程。</li>
<li><strong>逐步更新页表</strong>：当系统决定回收某个页时，内核可以延迟对页表的更新，以减少频繁的页表更新操作。</li>
</ul>
<p>内存回收在释放系统资源的同时，也带来了一定的性能开销。内核必须在释放内存和保持系统性能之间找到平衡。如果内存回收策略过于激进，可能会导致频繁的页面置换和磁盘交换操作，从而拖慢系统性能。反之，如果内存回收不足，则系统可能会遇到内存不足的问题，影响应用程序的正常运行。</p>
<hr>
<h2 id="发布-订阅模型-publish-subscribe">发布-订阅模型 (Publish-Subscribe)
</h2><p>在<strong>发布-订阅</strong>（Publish-Subscribe）模型中，<strong>写入者</strong>（发布者）会初始化一个数据项，然后通过 <code>rcu_assign_pointer</code> 来发布一个指向该数据项的指针。<strong>读取者</strong>（订阅者）通过 <code>rcu_dereference</code> 来获取并读取这个指针指向的数据项。这两个原语分别保证了数据的发布和读取过程的正确性。</p>
<ul>
<li><strong><code>rcu_assign_pointer</code></strong>: 该函数负责将一个新初始化的指针赋值给全局可见的指针，确保在写操作完成之后，该指针所指向的数据才对读取者可见。</li>
<li><strong><code>rcu_dereference</code></strong>: 读取者在访问 RCU 临界区中的指针时使用 <code>rcu_dereference</code>，确保数据在正确的时间顺序下被访问。</li>
</ul>
<p>这种模式常常与<strong>存在性保证</strong>（existence guarantees）结合使用，以便发布新版本的数据项、并在保证旧版本不被并发访问的情况下回收它们。这一模式允许系统中的多个读取者在并发的情况下访问数据，同时允许写入者在后台安全地更新或替换数据项。</p>
<p>Linux 内核中的一个经典例子是 <strong>动态替换系统调用</strong>。在某些体系结构（例如 PowerPC Cell 架构）中，系统会在运行时向系统调用表追加新的系统调用。这个扩展表的指针通过 <code>rcu_assign_pointer</code> 发布，确保扩展表的初始化完成后，读取者才能正确访问扩展表中的内容。</p>
<p>在执行系统调用时，内核会首先调用 <code>rcu_read_lock</code> 进入 RCU 临界区，然后通过 <code>rcu_dereference</code> 来读取系统调用表的指针，确保系统调用表的扩展部分在被使用时已完全初始化。如果需要修改扩展表（例如撤回系统调用），内核会先将扩展表的指针设置为 <code>NULL</code>，确保不再有线程访问扩展表中的内容，随后调用 <code>synchronize_rcu</code>，等待所有正在执行的 RCU 临界区结束。这样确保没有线程会继续执行那些已经被移除的系统调用。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="kt">syscall_t</span> <span class="o">*</span><span class="n">table</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="kt">spinlock_t</span> <span class="n">table_lock</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">int</span> <span class="nf">invoke_syscall</span><span class="p">(</span><span class="kt">int</span> <span class="n">number</span><span class="p">,</span> <span class="kt">void</span> <span class="o">*</span><span class="n">args</span><span class="p">...)</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">syscall_t</span> <span class="o">*</span><span class="n">local_table</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="kt">int</span> <span class="n">r</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="nf">rcu_read_lock</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    <span class="n">local_table</span> <span class="o">=</span> <span class="nf">rcu_dereference</span><span class="p">(</span><span class="n">table</span><span class="p">);</span>  <span class="c1">// 获取最新的系统调用表
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">if</span> <span class="p">(</span><span class="n">local_table</span> <span class="o">!=</span> <span class="nb">NULL</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">r</span> <span class="o">=</span> <span class="n">local_table</span><span class="p">[</span><span class="n">number</span><span class="p">](</span><span class="n">args</span><span class="p">);</span>     <span class="c1">// 执行系统调用
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="nf">rcu_read_unlock</span><span class="p">();</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">r</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kt">void</span> <span class="nf">retract_table</span><span class="p">()</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="kt">syscall_t</span> <span class="o">*</span><span class="n">local_table</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="nf">spin_lock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">table_lock</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    <span class="n">local_table</span> <span class="o">=</span> <span class="n">table</span><span class="p">;</span>
</span></span><span class="line"><span class="cl">    <span class="nf">rcu_assign_pointer</span><span class="p">(</span><span class="o">&amp;</span><span class="n">table</span><span class="p">,</span> <span class="nb">NULL</span><span class="p">);</span>      <span class="c1">// 将系统调用表指针设置为 NULL
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="nf">spin_unlock</span><span class="p">(</span><span class="o">&amp;</span><span class="n">table_lock</span><span class="p">);</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="nf">synchronize_rcu</span><span class="p">();</span>                     <span class="c1">// 等待所有读取操作结束
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="nf">kfree</span><span class="p">(</span><span class="n">local_table</span><span class="p">);</span>                    <span class="c1">// 释放旧的系统调用表
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="p">}</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>发布-订阅模式关键在于：</p>
<ul>
<li><strong>同步与并发保证</strong>: 发布的指针在 RCU 临界区内能够被读取者并发访问，而不会导致数据竞态问题。使用 <code>rcu_assign_pointer</code> 和 <code>rcu_dereference</code> 能够确保在多处理器系统上数据的发布和读取过程中的内存屏障和编译器指令正确执行。</li>
<li><strong>旧版本的数据管理</strong>: 当写入者需要发布新版本的数据时，旧版本的数据仍可能被读取者访问，因此 RCU 提供了确保在读取者完成访问后安全地回收旧数据的机制。</li>
<li><strong>高效性</strong>: 发布-订阅模式结合 RCU 能够在极少锁开销的情况下实现高并发的读写分离操作，大大提高系统的吞吐量。</li>
</ul>
<hr>
<h2 id="cache-miss">Cache miss
</h2><p>在多处理器系统中，<strong>Cache miss</strong> 是影响性能的重要因素。传统的同步方法（如互斥锁、读写锁等）和 <strong>RCU（Read-Copy-Update）</strong> 方法在处理数据结构时，产生 Cache miss 的概率差异主要来源于两者对共享数据访问的方式和内存一致性的处理方式不同。</p>
<p>传统同步方法，尤其是使用锁机制的场景中，多个线程或处理器为了读取或修改共享数据，需要通过加锁来保护数据的完整性。在这种情况下，容易产生 Cache miss，主要有以下几个原因：</p>
<ul>
<li><strong>写-写竞争</strong>：多个处理器试图同时写入共享变量时，缓存一致性协议需要通过无效化其他处理器的缓存来保证一致性。比如，一个处理器写入某个缓存行的数据后，其他处理器需要重新加载该缓存行，导致 <strong>写 miss</strong> 频繁出现。</li>
<li><strong>写-读竞争</strong>：一个处理器正在写某个共享变量时，其他处理器可能正试图读取这个变量。每当写操作发生时，读取该变量的处理器需要重新加载最新的数据到它的缓存中，造成 Cache miss。</li>
<li><strong>锁的开销</strong>：当多个处理器竞争同一个锁时，锁变量本身也会被频繁读写，导致锁所在的缓存行失效，从而引发 Cache miss。</li>
</ul>
<p>这些竞争加剧了缓存行在多个处理器之间的传输，增加了缓存失效（Cache miss）的可能性。</p>
<p>RCU 提供了一种优化读操作的机制，减少了缓存一致性协议带来的负面影响。它的工作原理是通过“读者不阻塞写者，写者不阻塞读者”的方式来管理并发数据访问，具体来说有以下几种特性：</p>
<ul>
<li><strong>读者不加锁</strong>：RCU 允许多个读者同时读取数据，而不需要对共享数据加锁。这样，读操作就不会引发任何缓存一致性问题，也不会导致缓存行失效，因为读者访问的是共享数据的快照，不会修改数据。这大大减少了读操作的 Cache miss。</li>
<li><strong>写操作延迟并且分阶段进行</strong>：RCU 在写操作时，会先创建一个数据的副本（Copy），然后修改这个副本。当没有读者在访问旧的数据时，才会进行数据的更新（Update），将新版本替换旧版本。由于读者和写者之间不直接竞争缓存行，写操作发生时不会影响读者，从而减少了 Cache miss。</li>
<li><strong>批量更新</strong>：RCU 通常会将多个更新操作批量执行，而不是频繁地对共享数据进行修改。这种批量操作降低了写操作触发的缓存失效，从而降低了 Cache miss 的概率。</li>
</ul>
<div class="table-wrapper"><table>
  <thead>
      <tr>
          <th style="text-align: center">传统同步方法</th>
          <th style="text-align: left">由于频繁的读写竞争、缓存一致性维护，以及锁的使用，导致缓存失效较多，从而增加了 Cache miss 的频率。</th>
      </tr>
  </thead>
  <tbody>
      <tr>
          <td style="text-align: center"><strong>RCU 方法</strong></td>
          <td style="text-align: left">通过减少读操作的干扰和写操作的延迟更新，避免了读写竞争，因而大幅减少了 Cache miss。</td>
      </tr>
  </tbody>
</table></div>
<p>RCU 通过“读-写分离”和“数据复制”机制有效地减少了处理器间的缓存竞争，尤其是在多线程环境中，大量的读操作不会引发 Cache miss，这使得它在高并发场景中表现出色。</p>
<hr>
<h2 id="间接访问indirection">间接访问（indirection）
</h2><p>间接访问（indirection）在 RCU 设计中是为了确保 <strong>原子性和一致性</strong>，使得更新操作对读者看来是原子的，而不会暴露出“更新中的状态”。</p>
<p>在直接存储的模式下，如果对某个对象进行写操作，比如在 PID 表中直接存储 <code>process_t</code> 实例，那么更新 <code>process_t</code> 的各个字段就会发生在原对象上。这样一来，读者可能会在对象更新还未完成时，读取到尚未完全初始化的对象，这就是所谓的“中间状态”。</p>
<p>举个例子，假设一个 <code>process_t</code> 对象有多个字段需要逐一更新。如果 PID 表直接存储了这个对象的实例：</p>
<ul>
<li>当写者正在修改 <code>process_t</code> 的字段时，某个读者可能正在读取该对象，读取的字段可能只被部分更新。</li>
<li>这会导致不一致的读取情况，比如某个字段是旧值，而另一个字段是新值。这在多线程或并发环境中可能会引发严重的问题，因为读者期望读取的是一个一致的、完全更新的对象。</li>
</ul>
<p>为了避免这种情况，RCU 使用间接访问：PID 表存储的是指向 <code>process_t</code> 的<strong>指针</strong>，而不是 <code>process_t</code> 实例本身。这种方式确保更新过程可以通过<strong>更换指针</strong>来实现，从而使得新对象的发布是<strong>原子的</strong>：</p>
<ul>
<li><strong>更新副本</strong>：当需要更新 <code>process_t</code> 时，写者不会直接修改现有的 <code>process_t</code>，而是创建一个新的 <code>process_t</code> 副本，完全更新新对象的所有字段。</li>
<li><strong>发布新指针</strong>：在新对象的所有字段都更新完毕后，写者将 PID 表中指向 <code>process_t</code> 的指针更新为新对象的地址。这一操作是原子的：所有的字段更新都是<strong>一次性发布</strong>的，不会暴露出中间状态。</li>
</ul>
<p>在这个过程中，指针充当了一个“指向新状态”的媒介。由于指针的更换是原子的，任何新的读者都会看到<strong>完整的新对象</strong>，而不是一个正在更新的对象。示例：</p>
<ul>
<li>初始状态：PID 表中的指针 <code>ptr</code> 指向 <code>process_t_A</code>。</li>
<li>写操作：创建 <code>process_t_B</code> 副本并更新所有字段。</li>
<li>指针更新：将 <code>ptr</code> 更新为指向 <code>process_t_B</code>。此时，所有读者读取到的都是 <code>process_t_B</code>，不可能再读取到部分更新的 <code>process_t_A</code>。</li>
</ul>
<p>总而言之，通过间接访问：</p>
<ul>
<li>可以确保数据的更新对读者来说是一次性的、原子的，避免了不一致的读取情况。</li>
<li>读者在读取数据时，始终会看到一个完全初始化的数据对象，而不会被暴露给“部分更新”或“中间状态”。</li>
</ul>
<p>在多线程编程中，使用间接访问为数据一致性提供了重要保障，这也解释了为什么在 RCU 中间接访问是一个常见的设计模式。</p>
<hr>
<h2 id="正课部分">正课部分
</h2><h2 id="使用锁带来的问题">使用锁带来的问题
</h2><p>今天的话题是如何在多核CPU计算机上获得好的性能，这是一个非常有趣，深入且令人着迷的话题。今天我们只会涉及这个话题的很小的一个部分，也就是在面对内核中需要频繁读但是不需要频繁写的共享数据时，如何获得更好的性能。</p>
<p>在不同的场景下有不同的方法可以在多核CPU的机器上获得更好的性能，我们今天要看的是Linux的RCU，它对于需要频繁读的内核数据来说是一种非常成功的方法。</p>
<p>如果你有一个现代的计算机，或许包含了4、8、16、64个并行运行的CPU核，这些CPU核共享了内存数据，操作系统内核将会是一个并行运行的程序。如果你想要获得好的性能，你需要确保内核能尽可能的在多个CPU核上并行的完成它的工作。</p>
<p>如果你能将内核并行的运行在8个CPU核上，并且它们都能完成有效的工作，那么相比运行在单个CPU核上，你就能获得8倍的性能。从理论上来说，这明显是可能的。</p>
<p>如果你在内核中有大量的进程，那就不太用担心，在不做任何额外工作的前提下，这些进程极有可能是并行运行的。另一方面，如果你有很多应用程序都在执行系统调用，很多时候，不同的应用程序执行的不同系统调用也应该是相互独立的，并且在很多场景下应该在相互不影响的前提下运行。</p>
<p>例如，通过fork产生的两个进程，或者读取不同pipe的两个进程，或者读写不同文件的两个进程。表面上看，这些进程之间没有理由会相互影响，也没有理由不能并行运行并获得n倍的吞吐量。</p>
<p>但问题是内核中包含了大量的共享数据。</p>
<p>出于一些其他的原因，内核共享了大量的资源，例如内存，CPU，磁盘缓存，inode缓存，这些东西都在后台被不同的进程所共享。这意味着，即使两个完全不相关的进程在执行两个系统调用，如果这两个系统调用需要分配内存或使用磁盘缓存或者涉及到线程调度决策，它们可能最终会使用内核中相同的数据结构，因此我们需要有办法能让它们在使用相同数据的同时，又互不影响。</p>
<p>在过去的许多年里，人们付出了巨大的努力来让内核中的这些场景能更快的运行。</p>
<p>我们之前看过其中一种可以保证正确性的方法，也就是spinlock。</p>
<p>spinlock很直观，它的工作就是当两个进程可能会相互影响时，阻止并行运行。所以spinlock的直接效果就是降低性能。它使得正确性有了保障，但是又绝对的阻止了并行执行，这并不总是能令人满意。</p>
<p>今天我们会关注需要频繁读的数据，也就是说你的数据主要是在被读取，相对来说很少被写入。我将使用单链表来作为主要的例子。</p>
<p>对于单链表，会存在一个指向头指针（head）的全局变量，之后是一些链表元素，每个链表元素都包含了一个数据，假设是字符串。第一个链表元素包含了“hello”。每个链表元素还包含了一个next指针，指向了下一个链表元素。最后一个链表元素的next指针指向空指针。</p>
<p>接下来我们假设对于这个链表的大部分操作是读，比如说内核线程大部分时候只会扫描链表来找到某些数据，而不会修改链表。假设一个写请求都没有的话，我们就根本不必担心这个链表，因为它是完全静态的，它从来都不会更新，我们可以自由的读它。</p>
<p>但是接下来我们假设每隔一会，一些其他的线程会来修改链表元素中的数据；删除一个链表元素；又或者是在某个位置插入链表元素。所以尽管我们关注的主要是读操作，我们也需要关心写操作，我们需要保证读操作在面对写操作时是安全的。</p>
<p>在XV6中，我们是通过锁来保护这个链表。</p>
<p>在XV6中，不只是修改数据的线程，读取数据的线程也需要获取锁，因为我们需要排除当我们在读的时候某人正在修改链表的可能，否则的话会导致读取数据的线程可能读到更新一半的数据或者是读到一个无效的指针等等，所以XV6使用了锁。</p>
<p>但是使用锁有个缺点，如果通常情况下没有修改数据的线程，那么意味着每次有一个读取数据的线程，都需要获取一个排他的锁。XV6中的spinlock是排他的，即使只是两个读取数据的线程也只能一次执行一个线程。</p>
<p>所以一种改进这里场景的方法是使用一种新的锁，它可以允许多个读取线程和一个写入线程。接下来我们来看看这种锁，不仅因为它是有趣的，也因为它的不足促成了对于RCU的需求。</p>
<hr>
<h2 id="读写锁-read-write-lock">读写锁 (Read-Write Lock)
</h2><p>这种锁被称为读写锁（Read-Write Lock），它的接口相比spinlock略显复杂。</p>
<p>如果只是想要读取数据，那么可以调用r_lock，将锁作为参数传入，同样的还会有个r_unlock，数据的读取者使用这些接口。数据的写入者调用w_lock和w_unlock接口。</p>
<p>这里的语义是，要么你可以有多个数据的读取者获取了读锁，这样可以获得并行执行读操作的能力；要么你只能有一个数据写入者获取了写锁。但是不能两种情况同时发生，读写锁排除了某人获取了数据的写锁，同时又有别人获取读锁的可能性。</p>
<p>你要么只有一个数据写入者，要么有多个数据读取者，不可能有别的可能。</p>
<blockquote>
<p>学生提问：当某人持有了读锁时，读写锁是采用什么方案来阻止其他人写入数据的？</p>
<p>Robert教授：并没有什么方案，这就像XV6的锁一样。我们这里讨论的是由值得信赖且负责的开发人员编写的内核代码，所以就像XV6的spinlock一样，如果使用锁的代码是不正确的，那么结果就是不正确的，这是内核代码典型的编写方式，你只能假设开发内核的人员遵循这里的规则。</p>
</blockquote>
<p>如果我们有一个大部分都是读取操作的数据结构，我们会希望能有多个用户能同时使用这个数据结构，这样我们就可以通过多核CPU获得真正的性能提升。</p>
<p>如果没有其他问题的话，那么读写锁就可以解决今天的问题，我们也没有必要读<a class="link" href="https://pdos.csail.mit.edu/6.828/2020/readings/rcu-decade-later.pdf"  target="_blank" rel="noopener"
    >RCU这篇论文</a>。但实际上如果你深入细节，你会发现当你使用读写锁时，尤其对于大部分都是读取操作的数据结构，会有一些问题。为了了解实际发生了什么，我们必须看一下读写锁的代码实现。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="c1">//A simplified version of Linux&#39;s read/write lock.
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl"><span class="c1">//n=0  -&gt; not locked
</span></span></span><span class="line"><span class="cl"><span class="c1">//n=-1 -&gt; locked by one writer
</span></span></span><span class="line"><span class="cl"><span class="c1">//n&gt;0  -&gt; locked by n readers
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="k">struct</span> <span class="n">rwlock</span><span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="kt">int</span> <span class="n">n</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span><span class="o">:</span>
</span></span><span class="line"><span class="cl"><span class="nf">r_lock</span><span class="p">(</span><span class="n">l</span><span class="p">)</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">  <span class="k">while</span> <span class="mi">1</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">l</span><span class="o">-&gt;</span><span class="n">n</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">       <span class="k">continue</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="nf">CAS</span><span class="p">(</span><span class="o">&amp;</span><span class="n">l</span><span class="o">-&gt;</span><span class="n">n</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="err">×</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">       <span class="k">return</span>
</span></span><span class="line"><span class="cl"><span class="c1">//CAS(p,a,b)is atomic compare-and-swap instruction
</span></span></span><span class="line"><span class="cl"><span class="c1">//if *p ==a,set *p = b,return true
</span></span></span><span class="line"><span class="cl"><span class="c1">//else return false
</span></span></span><span class="line"><span class="cl"><span class="c1"></span><span class="nf">w_lock</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">  <span class="k">while</span> <span class="mi">1</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="nf">CAS</span><span class="p">(</span><span class="o">&amp;</span><span class="n">l</span><span class="o">-&gt;</span><span class="n">n</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      <span class="k">return</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>Linux实际上有读写锁的实现，上面是一种简化了的Linux代码。首先有一个结构体是rwlock，这与XV6中的lock结构体类似。rwlock结构体里面有一个计数器n，</p>
<ul>
<li>如果n等于0那表示锁没有以任何形式被被任何人持有</li>
<li>如果n等于-1那表示当前有一个数据写入者持有写锁</li>
<li>如果n大于0表示有n个数据读取者持有读锁。我们需要记录这里的数字，因为我们只有在n减为0的时候才能让数据写入者持有写锁。</li>
</ul>
<p>r_lock函数会一直在一个循环里面等待数据写入者释放锁。</p>
<p>首先它获取读写锁中计数器n的拷贝，如果n的拷贝小于0的话那意味着存在一个数据写入者，我们只能继续循环以等待数据写入者退出。</p>
<p>如果n的拷贝不小于0，我们会增加读写锁的计数器。但是我们只能在读写锁的计数器仍然大于等于0的时候，对其加1。</p>
<p>所以我们不能直接对n加1，因为如果一个数据写入者在我们检查n和我们增加n之间潜入了，那么我们有可能在数据写入者将n设置为-1的同时，将n又加了1。所以我们只能在检查完n大于等于0，且n没有改变的前提下，将其加1。</p>
<p>人们通过利用特殊的原子指令来实现这一点，我们之前在看XV6中spinlock的实现时看过类似的指令（注，详见10.7中的test_and_set指令）。</p>
<p>其中一个使用起来很方便的指令是compare-and-swap（CAS）。CAS接收三个参数，第一个参数是内存的某个地址，第二个参数是我们认为内存中该地址持有的数值，第三个参数是我们想设置到内存地址的数值。</p>
<p>CAS的语义是，硬件首先会设置一个内部的锁，使得一个CAS指令针对一个内存地址原子的执行；之后硬件会检查当前内存地址的数值是否还是x；如果是的话，将其设置为第三个参数，也就是x+1，之后CAS指令会返回1；如果不是的话，并不会改变内存地址的数值，并返回0。</p>
<p>这里必须是原子性，因为这里包含了两个操作，首先是检查当前值，其次是设置一个新的数值。</p>
<blockquote>
<p>学生提问：有没有可能计算x的过程中，发生了一个中断？</p>
<p>Robert教授：你是指我们在执行CAS指令之前计算它的第三个参数的过程中发生中断吗？CAS实际上是一个指令，如果中断发生在我们计算x+1的过程中，那么意味着我们还没有调用CAS，这时包括中断在内的各种事情都可能发生。</p>
<p>如果我们在最初读取n的时候读到0，那么不管发不发生中断，我们都会将1作为CAS的第三个参数传入，因为中断并不会更改作为本地变量的x，所以CAS的第二个和第三个参数会是0和1。如果n还是0，我们会将其设置为1，这是我们想看到的；如果n不是0，那么CAS并不会更新n。</p>
<p>如果这里没有使用本地变量x，那么就会有大问题了，因为n可能在任意时间被修改，所以我们需要在最开始在本地变量x中存储n的一个固定的值。</p>
</blockquote>
<p>上面介绍了w_lock与r_lock同时调用的场景。多个r_lock同时调用的场景同样也很有趣。</p>
<p>假设n从0开始，当两个r_lock同时调用时，我们希望当两个r_lock都返回时，n变成2，因为我们希望两个数据读取者可以并行的使用数据。两个r_lock在最开始都将看到n为0，并且都会通过传入第二个参数0，第三个参数1来调用CAS指令，但是只有一个CAS指令能成功。</p>
<p>CAS是一个原子操作，一次只能发生一个CAS指令。不管哪个CAS指令先执行，将会看到n等于0，并将其设置为1。另一个CAS指令将会看到n等于1，返回失败，并回到循环的最开始，这一次x可以读到1，并且接下来执行CAS的时候，第二个参数将会是1，第三个参数是2，这一次CAS指令可以执行成功。</p>
<p>最终两次r_lock都能成功获取锁，其中一次r_lock在第一次尝试就能成功，另一次r_lock会回到循环的最开始再次尝试并成功。</p>
<blockquote>
<p>学生提问：如果开始有一堆数据读取者在读，之后来了一个数据写入者，但是又有源源不断的数据读取者加入进来，是不是就轮不到数据写入者了？</p>
<p>Robert教授：如果多个数据读取者获取了锁，每一个都会通过CAS指令将n加1，现在n会大于0。如果这时一个数据写入者尝试要获取锁，它的CAS指令会将n与0做对比，只有当n等于0时，才会将其设置为-1。</p>
<p>但是因为存在多个数据读取者，n不等于0，所以CAS指令会失败。数据写入者会在w_lock的循环中不断尝试并等待n等于0，如果存在大量的数据读取者，这意味着数据写入者有可能会一直等待。这是这种锁机制的一个缺陷。</p>
<p>学生提问：在刚刚两个数据读取者要获取锁的过程中，第二个数据读取者需要再经历一次循环，这看起来有点浪费，如果有多个数据读取者，那么它们都需要重试。</p>
<p>Robert教授：你说到了人们为什么不喜欢这种锁的点子上了。即使没有任何的数据写入者，仅仅是在多个CPU核上有大量的数据读取者，r_lock也可能会有非常高的代价。</p>
</blockquote>
<p>在一个多核的系统中，每个CPU核都有一个关联的cache，也就是L1 cache。每当CPU核读写数据时，都会保存在cache中。除此之外，还有一些内部连接的线路使得CPU可以彼此交互，因为如果某个CPU核修改了某个数据，它需要告诉其他CPU核不要去缓存这个数据，这个过程被称为(cache) invalidation。</p>
<p>如果有多个数据读取者在多个CPU上同时调用r_lock，它们都会读取读写锁的计数l-&gt;n，并将这个数据加载到CPU的cache中，它们也都会调用CAS指令，但是第一个调用CAS指令的CPU会修改l-&gt;n的内容。作为修改的一部分，它需要使得其他CPU上的cache失效。</p>
<p>所以执行第一个CAS指令的CPU需要通过线路发送invalidate消息给其他每一个CPU核，之后其他的CPU核在执行CAS指令时，需要重新读取l-&gt;n，但是这时CAS指令会失败，因为l-&gt;n已经等于1了，但x还是等于0。</p>
<p>之后剩下的所有数据读取者都会回到循环的最开始，重复上面的流程，但这一次还是只有一个数据读取者能成功。</p>
<p>假设有n个数据读取者，那么每个r_lock平均需要循环n/2次，每次循环都涉及到O(n)级别的CPU消息，因为至少每次循环中所有CPU对于l-&gt;n的cache需要被设置为无效。</p>
<p>这意味着，对于n个CPU核来说，同时获取一个锁的成本是O(n^2)，当你为一份数据增加CPU核时，成本以平方增加。</p>
<p>这是一个非常糟糕的结果，因为你会期望如果有10个CPU核完成一件事情，你将获得10倍的性能，尤其现在还只是读数据并没有修改数据。</p>
<p>你期望它们能真正的并行运行，当有多个CPU核时，每个CPU核读取数据的时间应该与只有一个CPU核时读取数据的时间一致，这样并行运行才有意义，因为这样你才能同时做多件事情。但是现在，越多的CPU核尝试读取数据，每个CPU核获取锁的成本就越高。</p>
<p>对于一个只读数据，如果数据只在CPU的cache中的话，它的访问成本可能只要几十个CPU cycle。但是如果数据很受欢迎，由于O(n^2)的效果，光是获取锁就要消耗数百甚至数千个CPU cycle，因为不同CPU修改数据（注，也就是读写锁的计数器）需要通过CPU之间的连线来完成缓存一致的操作。</p>
<p>所以这里的读写锁，将一个原本成本很低的读操作，因为要修改读写锁的l-&gt;n，变成了一个成本极高的操作。如果你要读取的数据本身就很简单，这里的锁可能会完全摧毁任何并行带来的可能的性能提升。</p>
<p>读写锁糟糕的性能是RCU存在的原因，因为如果读写锁足够有效，那么就没有必要做的更好。</p>
<p>除了在有n个CPU核时，r_lock的成本是O(n^2)之外，这里的读写锁将一个本来可以缓存在CPU中的，并且可能会很快的只读的操作，变成了需要修改锁的计数器l-&gt;n的操作。</p>
<p>如果我们写的是可能与其他CPU核共享的数据，写操作通常会比读操作成本高得多。因为读一个未被修改的数据可以在几个CPU cycle内就从CPU cache中读到，但是修改可能被其他CPU核缓存的数据时，需要涉及CPU核之间的通信来使得缓存失效。</p>
<p>不论如何修改数据结构，任何涉及到更改共享数据的操作对于性能来说都是灾难。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="nf">r_lock</span><span class="p">(</span><span class="n">l</span><span class="p">)</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">  <span class="k">while</span> <span class="mi">1</span><span class="o">:</span>
</span></span><span class="line"><span class="cl">    <span class="n">x</span> <span class="o">=</span> <span class="n">l</span><span class="o">-&gt;</span><span class="n">n</span> <span class="c1">//THIS
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>    <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">       <span class="k">continue</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="nf">CAS</span><span class="p">(</span><span class="o">&amp;</span><span class="n">l</span><span class="o">-&gt;</span><span class="n">n</span><span class="p">,</span><span class="n">X</span><span class="p">,</span><span class="err">×</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">       <span class="k">return</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>所以r_lock中最关键的就是它对共享数据做了一次写操作。所以我们期望找到一种方式能够在读数据的同时，又不需要写数据，哪怕是写锁的计数器也不行。这样读数据实际上才是一个真正的只读操作。</p>
<hr>
<h2 id="rcu实现1---基本实现">RCU实现(1) - 基本实现
</h2><p>一种可能的解决方案是：数据读取者完全不使用锁。</p>
<p>在有些场景数据读取者可以直接读数据，只有数据的写入者才需要锁。我们接下来快速的看一下能不能让数据读取者在不上锁的时候直接读取链表。</p>
<p>假设我们有个链表，链表元素中存的数据是字符串，我们将读取链表中的数据。如果没有数据的写入者，那么不会有任何问题。</p>
<p>接下来我们看一下存在数据写入者时的三种可能场景：</p>
<ul>
<li>首先是数据的写入者只修改了链表元素的内容，将链表元素中的字符串改成了其他的字符串。</li>
<li>第二种场景是数据写入者插入了一个链表元素。</li>
<li>第三种场景是数据写入者删除了一个链表元素。</li>
</ul>
<p>因为RCU需要分别考虑这三种场景，我们将会分别审视这三种场景并看一下同时发生数据的读写会有什么问题？</p>
<ul>
<li>
<p>如果数据写入者想要修改链表元素内的字符串，而数据读取者可能正在读取相同字符串。如果不做任何特殊处理，数据读取者可能会读到部分旧的字符串和部分新的字符串。这是我们需要考虑的一个问题。</p>
</li>
<li>
<p>如果数据写入者正在插入一个链表元素，假设要在链表头部插入一个元素，数据写入者需要将链表的头指针指向新元素，并将新元素的next指针指向之前的第一个元素。</p>
<p>这里的问题是，数据的写入者可能在初始化新元素之前，就将头指针指向新元素，也就是说这时新元素包含的字符串是无效的并且新元素的next指针指向的是一个无效的地址。这是插入链表元素时可能出错的地方。</p>
</li>
<li>
<p>如果数据写入者正在删除一个链表元素，我们假设删除的是第一个元素，所以需要将链表的头指针指向链表的第二个元素，之后再释放链表的第一个元素。</p>
<p>这里的问题是，如果数据读取者正好在读链表的第一个元素，而数据写入者又释放了这个元素，那么数据读取者看到的是释放了的元素，这个链表元素可能接下来被用作其他用途，从数据读取者的角度来说看到的是垃圾数据。</p>
</li>
</ul>
<p>如果我们完全不想为数据读取者提供任何锁，那么我们需要考虑这三个场景。我将不会讨论数据写入者对应的问题，因为在整个课程中我将会假设数据写入者在完成任何操作前，都会使用类似spinlock的锁。</p>
<p>我们不能直接让数据读取者在无锁情况下完成读取操作，但是我们可以修复上面提到的问题，这就带出了RCU（Read Copy Update）这个话题。</p>
<p>RCU是一种实现并发的特殊算法，它是一种组织数据读取者和写入者的方法，通过RCU数据读取者可以不用使用任何锁。RCU的主要任务就是修复上面的三种数据读取者可能会陷入问题的场景，它的具体做法是让数据写入者变得更加复杂一些，所以数据写入者会更慢一些。</p>
<p>除了锁以外它还需要遵循一些额外的规则，但是带来的好处是数据读取者因为可以不使用锁、不需要写内存而明显的变快。</p>
<p>在之前讨论的第一个场景中，数据写入者会更新链表元素的内容。RCU将禁止这样的行为，也就是说数据写入者不允许修改链表元素的内容。假设我们有一个链表，数据写入者想要更新链表元素E2。</p>
<p>现在不能直接修改E2的内容，RCU会创建并初始化一个新的链表元素。所以新的内容会写到新的链表元素中，之后数据写入者会将新链表元素的next指针指向E3，之后在单个的写操作中将E1的next指针指向新的链表元素。</p>
<p><img src="/p/mit6s081lec23/p68.png"
	width="1536"
	height="734"
	srcset="/p/mit6s081lec23/p68_hu4598649849026198163.png 480w, /p/mit6s081lec23/p68_hu4727774238858778511.png 1024w"
	loading="lazy"
	
		alt="p68"
	
	
		class="gallery-image" 
		data-flex-grow="209"
		data-flex-basis="502px"
	
></p>
<p>所以这里不是修改链表元素的内容，而是用一个包含了更新之后数据的新链表元素代替之前的链表元素。对于数据读取者来说，如果遍历到了E1并正在查看E1的next指针：</p>
<ul>
<li>要么看到的是旧的元素E2，这并没有问题，因为E2并没有被改变；</li>
<li>要么看到的是新版本的E2，这也没有问题，因为数据写入者在更新E1的next指针之前已经完全初始化好了新版本的E2。</li>
</ul>
<p>不管哪种情况，数据读取者都将通过正确的next指针指向E3。这里核心的点在于，数据读取者永远也不会看到一个正在被修改的链表元素内容。</p>
<blockquote>
<p>学生提问：旧的E2和E3之间的关系会被删除吗？</p>
<p>Robert教授：会被保留。这是个好问题，并且这也是RCU中较为复杂的主要部分，现在我们假设旧的E2被保留了。</p>
<p>学生提问：我们并不用担心E2和E3之间的关系，因为在普通的实现中，E2也会被释放，就算没有RCU我们也不用担心这里的关系，是吗（注，这里应该说的是GC会回收E2）？</p>
<p>Robert教授：这里的问题是，在我们更新E1的next指针时，部分数据读取者通过E1的旧的next指针走到了旧的E2，所以当完成更新时，部分数据读取者可能正在读取旧的E2，我们最好不要释放它。</p>
</blockquote>
<p>这里将E1的next指针从旧的E2切换到新的E2，在我（Robert教授）脑海里，我将其称为committing write。</p>
<p>这里能工作的部分原因是，单个committing write是原子的，从数据读取者的角度来说更新指针要么发生要么不发生。通过这一条不可拆分的原子指令，我们将E1的next指针从旧的E2切换到的新的E2。写E1的next指针完成表明使用的是新版本的E2。</p>
<p>这是对于RCU来说一个非常基本同时也是非常重要的技术，它表示RCU主要能用在具备单个committing write的数据结构上。这意味着一些数据结构在使用RCU时会非常的奇怪，例如一个双向链表，其中的每个元素都有双向指针，这时就不能通过单个committing write来删除链表元素，因为在大多数机器上不能同时原子性的更改两个内存地址。所以双向链表对于RCU来说不太友好。</p>
<p>相反的，树是一个好的数据结构。</p>
<p>如果我们要更新图中的节点，我们可以构造树的虚线部分，然后再通过单个committing write更新树的根节点指针，切换到树的新版本。</p>
<p>数据写入者会创建树中更新了的那部分，同时再重用树中未被修改的部分，最后再通过单个committing write，将树的根节点更新到新版本的树的根节点。</p>
<p><img src="/p/mit6s081lec23/p69.png"
	width="1130"
	height="622"
	srcset="/p/mit6s081lec23/p69_hu12919972555610845742.png 480w, /p/mit6s081lec23/p69_hu4206817635173802955.png 1024w"
	loading="lazy"
	
		alt="p69"
	
	
		class="gallery-image" 
		data-flex-grow="181"
		data-flex-basis="436px"
	
></p>
<p>但是对于其他的数据结构，就不一定像树一样能简单的使用RCU。以上就是实现RCU的第一部分。</p>
<hr>
<h2 id="rcu实现2---memory-barrier">RCU实现(2) - Memory barrier
</h2><p>在前一部分介绍的方法中，存在一个问题。在前一部分中，如果要更新E2的内容，需要先创建一个E2‘ 并设置好它的内容，然后将E2’ 的next指针指向E3，最后才会将E1的next指针指向E2’。</p>
<p>你们或许还记得在XV6中曾经介绍过（注，详见10.8），许多计算机中都不存在“之后”或者“然后”这回事，通常来说所有的编译器和许多微处理器都会重排内存操作。如果我们用C代码表示刚才的过程：</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="n">e</span> <span class="o">=</span> <span class="nf">alloc</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">e</span><span class="o">-&gt;</span> <span class="n">next</span> <span class="o">=</span> <span class="n">E3</span>
</span></span><span class="line"><span class="cl"><span class="n">E1</span><span class="o">-&gt;</span><span class="n">next</span> <span class="o">=</span> <span class="n">e</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>如果你测试这里的代码，它可能可以较好的运行，但是在实际中就会时不时的出错。</p>
<p>这里的原因是编译器或者计算机可能会重排这里的写操作，也有可能编译器或者计算机会重排数据读取者的读操作顺序。如果我们在初始化E2’的内容之前，就将E1的next指针设置成E2‘，那么某些数据读取者可能就会读到垃圾数据并出错。</p>
<p>所以实现RCU的第二个部分就是数据读取者和数据写入者都需要使用memory barriers，这里背后的原因是因为我们这里没有使用锁。对于数据写入者来说，memory barrier应该放置在committing write之前，</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="n">e</span> <span class="o">=</span> <span class="nf">alloc</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">e</span><span class="o">-&gt;</span> <span class="n">next</span> <span class="o">=</span> <span class="n">E3</span>
</span></span><span class="line"><span class="cl">    <span class="n">BARRIER</span>
</span></span><span class="line"><span class="cl"><span class="n">E1</span><span class="o">-&gt;</span><span class="n">next</span> <span class="o">=</span> <span class="n">e</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>这样可以告知编译器和硬件，先完成所有在barrier之前的写操作，再完成barrier之后的写操作。所以在E1设置next指针指向E2‘的时候，E2’必然已经完全初始化完了。</p>
<p>对于数据读取者，需要先将E1的next指针加载到某个临时寄存器中，我们假设r1保存了E1的next指针，之后数据读取者也需要一个memory barrier，然后数据读取者才能查看r1中保存的指针。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="n">r1</span> <span class="o">=</span> <span class="n">E1</span> <span class="o">-&gt;</span> <span class="n">next</span>
</span></span><span class="line"><span class="cl">    <span class="n">BARRIER</span>
</span></span><span class="line"><span class="cl"><span class="n">r1</span> <span class="o">-&gt;</span> <span class="n">x</span>
</span></span><span class="line"><span class="cl">   <span class="o">-&gt;</span> <span class="n">next</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>这里的barrier表明的意思是，在完成E1的next指针读取之前，不要执行其他的数据读取，这样数据读取者从E1的next指针要么可以读到旧的E2，要么可以读到新的E2‘。</p>
<p>通过barrier的保障，我们可以确保成功在r1中加载了E1的next指针之后，再读取r1中指针对应的内容。</p>
<p>因为数据写入者中包含的barrier确保了在committing write时，E2’已经初始化完成。如果数据读取者读到的是E2‘，数据读取者中包含的barrier确保了可以看到初始化之后E2’的内容。</p>
<blockquote>
<p>学生提问：什么情况下才可能在将E1的next指针加载到r1之前，就先读取r1中指针指向的内容？</p>
<p>Robert教授：我觉得你难住我了。一种可能是，不论r1指向的是什么，它或许已经在CPU核上有了缓存，或许一分钟之前这段内存被用作其他用途了，我们在CPU的缓存上有了E1-&gt;next对应地址的一个旧版本。</p>
<p>我不确定这是不是会真的发生，这里都是我编的，如果r1-&gt;x可以使用旧的缓存的数据，那么我们将会有大麻烦。</p>
<p>说实话我不知道这个问题的答案，呵呵。我课下会想一个具体的例子。</p>
</blockquote>
<hr>
<h2 id="rcu实现3---读写规则">RCU实现(3) - 读写规则
</h2><p>前面有同学也提到过，数据写入者会将E1的next指针从指向旧的E2切换到指向新的E2‘，但是可能有数据读取者在切换之前读到了旧的E2，并且仍然在查看旧的E2。</p>
<p>我们需要在某个时候释放旧的E2，但是最好不要在某些数据读取者还在读的时候释放。所以我们需要等待最后一个数据读取者读完旧的E2，然后才能释放旧的E2。</p>
<p>这就是RCU需要解决的第三个问题，数据写入者到底要等待多久才能释放E2？你可以想到好几种方法来实现这里的等待。</p>
<p>例如，我们可以为每个链表元素设置一个引用计数，并让数据读取者在开始使用链表元素时对引用计数加1，用完之后对引用计数减1，然后让数据写入者等待引用计数为0。</p>
<p>但是我们会第一时间就否定这个方案，因为RCU的核心思想就是在读数据的时候不引入任何的写操作，因为我们前面看过了，如果有大量的数据读取者同时更新引用计数，相应的代价将十分高。所以我们绝对不会想要有引用计数的存在。</p>
<p>另一种可能是使用自带垃圾回收（Garbage Collect）的编程语言。</p>
<p>在带有GC的编程语言中，你不用释放任何对象，相应的GC会记住是否有任何线程或者任何数据结构对于某个对象还存在引用。如果GC发现对象不可能再被使用时，就会释放对象。</p>
<p>这也是一种可能且合理的用来释放链表元素的方法。但是使用了RCU的Linux系统，并不是由带有GC的编程语言编写，并且我们也不确定GC能不能提升性能，所以这里我们也不能使用一个标准GC来释放E2。</p>
<p>RCU使用的是另一种方法，数据读取者和写入者都需要遵循一些规则，使得数据写入者可以在稍后再释放链表元素。规则如下：</p>
<ul>
<li>数据读取者不允许在context switch（注，是指线程切换的context switch，详见11.4）时持有一个被RCU保护的数据（也就是链表元素）的指针。所以数据读取者不能在RCU critical 区域内出让CPU。</li>
<li>对于数据写入者，它会在每一个CPU核都执行过至少一次context switch之后再释放链表元素。</li>
</ul>
<p>这里的第一条规则也是针对spin lock的规则，在spin lock的加锁区域内是不能出让CPU的。</p>
<p>第二条规则更加复杂点，但是相对来说也更清晰，因为每个CPU核都知道自己有没有发生context switch，所以第二条规则是数据写入者需要等待的一个明确条件。</p>
<p>数据写入者或许要在第二条规则上等待几个毫秒的时间才能确保没有数据读取者还在使用链表元素，进而释放链表元素。</p>
<p>人们创造了多种技术来实现上面第二条规则中的等待，<a class="link" href="https://pdos.csail.mit.edu/6.828/2020/readings/rcu-decade-later.pdf"  target="_blank" rel="noopener"
    >论文</a>里面讨论的最简单的一种方法是通过调整线程调度器，使得写入线程简短的在操作系统的每个CPU核上都运行一下，这个过程中每个CPU核必然完成了一次context switching。</p>
<p>因为数据读取者不能在context switch的时候持有数据的引用，所以经过这个过程，数据写入者可以确保没有数据读取者还在持有数据。</p>
<p>所以数据写入者的代码实际上看起来是这样的：</p>
<ul>
<li>首先完成任何对于数据的修改</li>
<li>之后调用实现了上面第二条规则synchronize_rcu函数</li>
<li>最后才是释放旧的链表元素</li>
</ul>
<p>synchronize_rcu迫使每个CPU核都发生一次context switch，所以在synchronize_rcu函数调用之后，由于前面的规则1，任何一个可能持有旧的E1 next指针的CPU核，都不可能再持有指向旧数据的指针，这意味着我们可以释放旧的链表元素。</p>
<p>你们可能会觉得synchronize_rcu要花费不少时间，可能要将近1个毫秒，这是事实并且不太好。</p>
<p>其中一种辩解的方法是：对于RCU保护的数据来说，写操作相对来说较少，写操作多花费点时间对于整体性能来说不会太有影响。</p>
<p>对于数据写入者不想等待的场景，可以调用另一个函数call_rcu，将你想释放的对象和一个执行释放的回调函数作为参数传入，RCU系统会将这两个参数存储到一个列表中，并立刻返回。</p>
<p>之后在后台，RCU系统会检查每个CPU核的context switch计数，如果每个CPU核都发生过context switch，RCU系统会调用刚刚传入的回调函数，并将想要释放的对象作为参数传递给回调函数。这是一种避免等待的方法，因为call_rcu会立即返回。</p>
<p>但是另一方面不推荐使用call_rcu，因为如果内核大量的调用call_rcu，那么保存call_rcu参数的列表就会很长，这意味着需要占用大量的内存，因为每个列表元素都包含了一个本该释放的指针。</p>
<p>在一个极端情况下，如果你不够小心，大量的调用call_rcu可能会导致系统OOM，因为所有的内存都消耗在这里的列表上了。所以如果不是必须的话，人们一般不会使用call_rcu。</p>
<blockquote>
<p>学生提问：这里的机制阻止了我们释放某些其他人还在使用的对象，但是并没有阻止数据读取者看到更新了一半的数据，对吗？</p>
<p>Robert教授：23.3中的基本实现阻止了你说的情况，在23.3中，我们并不是在原地更新链表元素，如果是的话绝对会造成你说的那种情况。</p>
<p>RCU不允许在原地更新数据，它会创建一个新的数据元素然后通过单个committing write替换原有数据结构中的旧数据元素。因为这里的替换是原子的，所以数据读取者看不到更新了一半的数据。</p>
<p>学生提问：上面提到的条件1，是不是意味着我们必须关注在RCU read crtical区域内的代码执行时间，因为它限制了CPU核在这个区域内不能context switch？</p>
<p>Robert教授：是的，在RCU区域内，数据读取者会阻止CPU发生context switch，所以你会想要让这个区域变得较短，这是个需要考虑的地方。</p>
<p>RCU使用的方式是，在Linux中本来有一些被普通锁或者读写锁保护的代码，然后某人会觉得锁会带来糟糕的性能问题，他会将Locking区域替换成RCU区域，尽管实际中会更加复杂一些。</p>
<p>Locking区域已经尽可能的短了，因为当你持有锁的时候，可能有很多个CPU核在等待锁，所以普通锁保护的区域会尽量的短。因为RCU区域通常是用来替代Lock区域，它也趋向于简短，所以通常情况下不用担心RCU区域的长短。</p>
<p>这里实际的限制是，数据读取者不能在context switch时持有指针指向被RCU保护的数据，这意味着你不能读磁盘，然后在等读磁盘返回的过程中又持有指针指向被RCU保护的数据。</p>
<p>所以通常的问题不是RCU区域的长短，而是禁止出让CPU。</p>
</blockquote>
<hr>
<h2 id="rcu用例代码">RCU用例代码
</h2><p>为了巩固前面介绍的内容，接下来看一段使用了RCU的简单代码。上半段是读取被RCU保护的链表 ，下半段代码是替换链表的第一个元素。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre tabindex="0" class="chroma"><code><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span></code></pre></td>
<td class="lntd">
<pre tabindex="0" class="chroma"><code class="language-c" data-lang="c"><span class="line"><span class="cl"><span class="c1">//list reader:
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>
</span></span><span class="line"><span class="cl"><span class="nf">rcu_read_lock</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">e</span> <span class="o">=</span> <span class="n">head</span>
</span></span><span class="line"><span class="cl"><span class="k">while</span><span class="p">(</span><span class="n">p</span><span class="p">){</span>
</span></span><span class="line"><span class="cl">  <span class="n">e</span> <span class="o">=</span> <span class="nf">rcu_dereference</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">  <span class="n">look</span> <span class="n">at</span> <span class="n">e</span><span class="o">-&gt;</span><span class="n">x</span> <span class="p">..</span>
</span></span><span class="line"><span class="cl">  <span class="n">e</span> <span class="o">=</span> <span class="n">e</span><span class="o">-&gt;</span><span class="n">next</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span><span class="line"><span class="cl"><span class="nf">rcu_read_unlock</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">              
</span></span><span class="line"><span class="cl"><span class="c1">//replace the first list element:
</span></span></span><span class="line"><span class="cl"><span class="c1"></span>              
</span></span><span class="line"><span class="cl"><span class="nf">acquire</span><span class="p">(</span><span class="n">lock</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">old</span> <span class="o">=</span> <span class="n">head</span>
</span></span><span class="line"><span class="cl"><span class="n">e</span> <span class="o">=</span> <span class="nf">alloc</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">e</span><span class="o">-&gt;</span><span class="n">x</span> <span class="o">=</span> <span class="p">...</span>
</span></span><span class="line"><span class="cl"><span class="n">e</span><span class="o">-&gt;</span><span class="n">next</span> <span class="o">=</span> <span class="n">head</span><span class="o">-&gt;</span><span class="n">next</span>
</span></span><span class="line"><span class="cl"><span class="nf">rcu_assign_pointer</span><span class="p">(</span><span class="o">&amp;</span><span class="n">head</span><span class="p">,</span><span class="n">e</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="nf">release</span><span class="p">(</span><span class="n">lock</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">              
</span></span><span class="line"><span class="cl"><span class="nf">synchronize_rcu</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nf">free</span><span class="p">(</span><span class="n">old</span><span class="p">)</span>
</span></span></code></pre></td></tr></table>
</div>
</div><p>数据读取位于rcu_read_lock和rcu_read_unlock之间，这两个函数几乎不做任何事情。</p>
<p>rcu_read_lock会设置一个标志位，表明如果发生了定时器中断，请不要执行context switch，因为接下来要进入RCU critical区域。</p>
<p>所以rcu_read_lock会设置一个标志位来阻止定时器中断导致的context switch，中断或许还会发生，但是不会导致context switch（注，也就是线程切换）。rcu_read_unlock会取消该标志位。</p>
<p>所以这是一个集成在RCU critical区域的计数器。rcu_read_lock和rcu_read_unlock因为几乎不做任何工作所以极其的快。</p>
<blockquote>
<p>注，这里有个问题，23.2中描述的读写锁慢的原因是因为在读数据的时候引入了写计数器的操作，这里同样也是需要额外的写操作，为什么这里不会有问题？这是因为读写锁的计数器是所有CPU共享的，而这里的标志位是针对每个CPU的，所以修改这里的标志位并不会引起CPU之间的缓存一致消息</p>
</blockquote>
<p>其中的while循环会扫描链表，rcu_dereference函数会插入memory barrier，它首先会从内存中拷贝e，触发一个memory barrier，之后返回指向e的指针。之后我们就可以读取e指针指向的数据内容，并走向下一个链表元素。数据读取部分非常简单。</p>
<p>数据写入部分更复杂点。</p>
<ul>
<li>RCU并不能帮助数据写入者之间避免相互干扰，所以必须有一种方法能确保一次只能有一个数据写入者更新链表。这里我们假设我们将使用普通的spinlock，所以最开始数据写入者获取锁。</li>
<li>如果我们要替换链表的第一个元素，我们需要保存先保存链表第一个元素的拷贝，因为最后我们需要释放它，所以有old=head。</li>
<li>接下来的代码执行的是之前介绍的内容，首先是分配一个全新的链表元素，之后是设置该链表元素的内容，设置该链表元素的next指针指向旧元素的next指针。</li>
<li>之后的rcu_assign_pointer函数会设置一个memory barrier，以确保之前的所有写操作都执行完，再将head指向新分配的链表元素e。</li>
<li>之后就是释放锁。</li>
<li>之后调用synchronize_rcu确保任何一个可能持有了旧的链表元素的CPU都执行一次context switch，因此这些CPU会放弃指向旧链表元素的指针。</li>
<li>最后是释放旧的链表元素。</li>
</ul>
<p>这里有件事情需要注意，在数据读取代码中，我们可以在循环中查看链表元素，但是我们不能将链表元素返回。例如，我们使用RCU的时候，不能写一个list_lookup函数来返回链表元素，也不能返回指向链表元素中数据的指针，也就是不能返回嵌入在链表元素中的字符串。</p>
<p>我们必须只在RCU critical区域内查看被RCU保护的数据，如果我们写了一个通用的函数返回链表元素，或许我们能要求这个函数的调用者也遵循一些规则，但是函数的调用者还是可能会触发context switch。</p>
<p>如果我们在函数的调用者返回之前调用了rcu_read_unlock，这将会违反23.5中的规则1，因为现在定时器中断可以迫使context switch，而被RCU保护的数据指针仍然被持有者。所以使用RCU的确会向数据读取者增加一些之前并不存在的限制。</p>
<blockquote>
<p>学生提问：这样是不是说我们不可能返回下标是i的元素所包含的内容？</p>
<p>Robert教授：可以返回一个拷贝，如果e-&gt;x是个字符串，那么我们可以返回一个该字符串的拷贝，这是没有问题的。</p>
<p>但是如果我们直接返回一个指针指向e-&gt;x，那就违反了RCU规则。实际上返回e中的任何指针都是错误的，因为我们不能在持有指向RCU保护数据的指针时，发生context switch。通常的习惯是直接在RCU critical区域内使用这些数据。</p>
</blockquote>
<p>接下来我将再简短的介绍性能。</p>
<p>如果你使用RCU，数据读取会非常的快，除了读取数据本身的开销之外就几乎没有别的额外的开销了。如果你的链表有10亿个元素，读取链表本身就要很长的时间，但是这里的时间消耗并不是因为同步（注，也就是类似加锁等操作）引起的。</p>
<p>所以你几乎可以认为RCU对于数据读取者来说没有额外的负担。唯一额外的工作就是在rcu_read_lock和rcu_read_unlock里面设置好不要触发context switch，并且在rcu_dereference中设置memory barrier，这些可能会消耗几十个CPU cycle，但是相比锁来说代价要小的多。</p>
<p>对于数据写入者，性能会更加的糟糕。</p>
<p>首先之前使用锁的时候所有的工作仍然需要做，例如获取锁和释放锁。其次，现在还有了一个可能非常耗时的synchronize_rcu函数调用。实际上在synchronize_rcu内部会出让CPU，所以代码在这不会通过消耗CPU来实现等待，但是它可能会消耗大量时间来等待其他所有的CPU核完成context switch。</p>
<p>所以基于数据写入时的多种原因，和数据读取时的工作量，数据写入者需要消耗更多的时间完成操作。如果数据读取区域很短（注，这样就可以很快可以恢复context switch），并且数据写入并没有很多，那么数据写入慢一些也没关系。所以当人们将RCU应用到内核中时，必须要做一些性能测试来确认使用RCU是否能带来好处，因为这取决于实际的工作负载。</p>
<p>你们应该已经看到了RCU并不是广泛通用的，你不能把所有使用spinlock并且性能很差的场景转化成使用 RCU，并获得更好的性能。</p>
<p>主要的原因是RCU完全帮不到写操作，甚至会让写操作更慢，只有当读操作远远多于写操作时才有可能应用RCU。</p>
<p>因为RCU有这样的限制：代码不能在sleep的时候持有指针指向被RCU保护的数据，所以这会使得一些代码非常奇怪。当一定要sleep的时候，在sleep结束之后需要重新进入RCU critical区域再次查找之前已经看过的数据，前提是这些数据还存在。所以RCU使得代码稍微复杂了一些。</p>
<p>另一方面可以直接应用RCU的数据结构在更新时，需要能支持单个操作的committing write。</p>
<p>你不能在原地更新数据，而是必须创建一个新的链表元素对象来替代之前的元素对象。所以单链表，树是可以应用RCU的数据结构，但是一些复杂的数据结构不能直接使用RCU。</p>
<p><a class="link" href="https://pdos.csail.mit.edu/6.828/2020/readings/rcu-decade-later.pdf"  target="_blank" rel="noopener"
    >论文</a>里面提到了一些更复杂的方法，例如sequence lock，可以在允许原地更新数据的同时，又不用数据读取者使用锁。但是这些方法要复杂一些，并且能够提升性能的场景也是受限的。</p>
<p>另一个小问题是，RCU并没有一种机制能保证数据读取者一定看到的是新的数据。</p>
<p>因为如果某些数据读取者在数据写入者替换链表元素之前，获取了一个指针指向被RCU保护的旧数据，数据读取者可能会在较长的时间内持有这个旧数据。大部分时候这都无所谓，但是论文提到了在一些场景中，人们可能会因为读到旧数据而感到意外。</p>
<p>作为一个独立的话题，你们或许会想知道对于一个写操作频繁的数据该如何提升性能。</p>
<p>RCU只关心读操作频繁的数据，但是这类数据只代表了一种场景。在一些特殊场景中，写操作频繁的数据也可以获取好的性能，但是我还不知道存在类似RCU这样通用的方法能优化写操作频繁的数据。不过仍然有一些思路可以值得借鉴。</p>
<ul>
<li>
<p>最有效的方法就是重新构造你的数据结构，这样它就不是共享的。有的时候共享数据完全是没必要的，一旦你发现数据共享是个问题，你可以尝试让数据不共享。</p>
</li>
<li>
<p>但是某些时候你又的确需要共享的数据，而这些共享数据并没有必要被不同的CPU写入。</p>
<p>实际上你们已经在lab中见过这样的数据，在locking lab的kalloc部分，你们重构了free list使得每个CPU核都有了一个专属的free list，这实际上就是将一个频繁写入的数据转换成了每个CPU核的半私有数据。</p>
<p>大部分时候CPU核不会与其他CPU核的数据有冲突，因为它们都有属于自己的free list。唯一的需要查看其他CPU核的free list的场景是自己的free list用光了。</p>
<p>有很多类似的例子用来处理内核中需要频繁写入的数据，例如Linux中的内存分配，线程调度列表。对于每个CPU核都有一套独立的线程对象以供线程调度器查看（注，详见11.8，线程对象存储在struct cpu中）。CPU核只有在自己所有工作都完成的时候才会查看其他CPU核的线程调度列表。</p>
<p>另一个例子是统计计数，如果你在对某个行为计数，但是计数变化的很频繁，同时又很少被读出，你可以重构你的计数器，使得每个CPU核都有一个独立的计数器，这样每个CPU核只需要更新属于自己的计数器。当你需要读取计数值时，你只需要通过加锁读出每个CPU核的计数器，然后再加在一起。</p>
<p>这些都是可以让写操作变得更快的方法，因为数据写入者只需要更新当前CPU核的计数器，但是数据读取者现在变得更慢了。如果你的计数器需要频繁写入，实际上通常的计数器都需要频繁写入，通过将更多的工作转换到数据读取操作上，这将会是一个巨大的收益。</p>
</li>
</ul>
<p>这里想说的是，即使我们并没有太讨论，但是的确存在一些技术在某些场合可以帮助提升需要频繁写入数据的性能。</p>
<p>最后总结一下，论文中介绍的RCU对于Linux来说是一个巨大的成功。</p>
<p>它在Linux中各种数据都有使用，实际中需要频繁读取的数据还挺常见的，例如block cache基本上就是被读取，所以一种只提升读性能的技术能够应用的非常广泛。</p>
<p>尽管已经有了许多有趣的并发技术，同步（synchronization）技术，RCU还是很神奇，因为它对数据读取者完全去除了锁和数据写入（注，这里说的数据写入是指类似读写锁时的计数值，但是RCU在读数据的时候还是需要写标志位关闭context switch，只是这里的写操作代价并不高），所以相比读写锁，RCU是一个很大的突破。</p>
<p>RCU能工作的核心思想是为资源释放（Garbage Collection）增加了grace period，在grace period中会确保所有的数据读取者都使用完了数据。所以尽管RCU是一种同步技术，也可以将其看做是一种特殊的GC技术。</p>
<blockquote>
<p>学生提问：为什么数据读取者可以读到旧数据呢？在RCU critical区域里，你看到的应该就是实际存在的数据啊？</p>
<p>Robert教授：通常来说这不是个问题。通常来说，你写代码，将1赋值给x，之后print ”done“。</p>
<p>在print之后，如果有人读取x，可能会看到你在将1赋值给x之前x的数值，这里或许有些出乎意料。而RCU允许这种情况发生，如果我们在使用RCU时，并将数据赋值改成list_replace，将包含1的元素的内容改成2。</p>
<p>在函数结束后，我们print ”done“。</p>
<p>如果一些其他的数据读取者在查看链表，它们或许刚刚看到了持有1的链表元素，之后它们过了一会才实际的读取链表元素内容，并看到旧的数值1（注，因为RCU是用替换的方式实现更新，数据读取者可能读到了旧元素的指针，里面一直包含的是旧的数值）。</p>
<p>所以这就有点奇怪了，就算添加memory barrier也不能避免这种情况。不过实际上大部分场景下这也没关系，因为这里数据的读写者是并发的，通常来说如果两件事情是并发执行的，你是不会认为它们的执行顺序是确定的。</p>
<p>但是论文中的确举了个例子说读到旧数据是有关系的，并且会触发一个实际的问题，尽管我并不太理解为什么会有问题。</p>
<p>学生提问：RCU之所以被称为RCU，是因为它的基本实现对吧？</p>
<p>Robert教授：Read-Copy-Update，是的我认为是因为它的基本实现，它不是在原地修改数据，你是先创建了一个拷贝再来更新链表。</p>
<p>学生提问：在介绍读写锁时，我们讨论了为了实现缓存一致需要O(n^2)时间。对于spinlock这是不是也是个问题，为什么我们在之前在介绍spinlock的时候没有讨论这个问题，是因为spinlock有什么特殊的操作解决了这个问题吗？</p>
<p>Robert教授：并没有，锁的代价都很高。如果没有竞争的话，例如XV6中的标准spinlock会非常快。但是如果有大量的CPU核在相同的时候要获取相同的锁就会特别的慢。存在一些其他的锁，在更高负载的时候性能更好，但是在更低负载的时候性能反而更差。这里很难有完美的方案。</p>
<p>学生提问：或许并不相关，可能存在不同操作系统之间的锁吗？</p>
<p>Robert教授：在分布式系统中，有一种锁可以存在于多个计算机之间。</p>
<p>一个场景是分布式数据库，你将数据分发给多个计算机，但是如果你想要执行一个transaction，并使用分布在多个计算机上的数据，你将需要从多个计算机上收集锁。</p>
<p>另一个场景是，有一些系统会尝试在独立的计算机之间模拟共享内存，比如说一个计算机使用了另一个计算机的内存，背后需要有一些工具能够使得计算机之间能交互并请求内存。</p>
<p>这样就可以在一个集群的计算机上运行一些现有的并行程序，而不是在一个大的多核计算机上，这样成本会更低。</p>
<p>这时需要对spinlock或者任何你使用的锁做一些额外的处理，人们发明了各种技术来使得锁能很好的工作，这些技术与我们介绍的技术就不太一样了，尽管避免性能损失的压力会更大。</p>
</blockquote>

</section>


    <footer class="article-footer">
    

    <section class="article-lastmod">
        <svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z"/>
  <circle cx="12" cy="12" r="9" />
  <polyline points="12 7 12 12 15 15" />
</svg>



        <span>
            最后更新于 Nov 12, 2024 12:44 &#43;0800
        </span>
    </section></footer>


    
        <link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css"integrity="sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI&#43;WdtXRGWt2kTvGFasHpSy3SV"crossorigin="anonymous"
            ><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"integrity="sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG&#43;vnGctmUb0ZY0l8"crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"integrity="sha384-&#43;VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4&#43;/RRE05"crossorigin="anonymous"
                defer
                >
            </script><script>
    window.addEventListener("DOMContentLoaded", () => {
        renderMathInElement(document.body, {
            delimiters: [
                { left: "$$", right: "$$", display: true },
                { left: "$", right: "$", display: false },
                { left: "\\(", right: "\\)", display: false },
                { left: "\\[", right: "\\]", display: true }
            ],
            ignoredClasses: ["gist"]
        });})
</script>
    
</article>

    

    

<aside class="related-content--wrapper">
    <h2 class="section-title">相关文章</h2>
    <div class="related-content">
        <div class="flex article-list--tile">
            
                
<article class="">
    <a href="/p/mit6s081lec22/">
        
        

        <div class="article-details">
            <h2 class="article-title">MIT6S081Lec22</h2>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/p/mit6s081lec21/">
        
        

        <div class="article-details">
            <h2 class="article-title">MIT6S081Lec21</h2>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/p/mit6s081lec20/">
        
        

        <div class="article-details">
            <h2 class="article-title">MIT6S081Lec20</h2>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/p/mit6s081lec19/">
        
        

        <div class="article-details">
            <h2 class="article-title">MIT6S081Lec19</h2>
        </div>
    </a>
</article>

            
                
<article class="">
    <a href="/p/mit6s081lec18/">
        
        

        <div class="article-details">
            <h2 class="article-title">MIT6S081Lec18</h2>
        </div>
    </a>
</article>

            
        </div>
    </div>
</aside>

     
    
        
    

    <footer class="site-footer">
    <section class="copyright">
        &copy; 
        
        2024 echudet
    </section>
    
    <section class="powerby">
        使用 <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a> 构建 <br />
        主题 <b><a href="https://github.com/CaiJimmy/hugo-theme-stack" target="_blank" rel="noopener" data-version="3.29.0">Stack</a></b> 由 <a href="https://jimmycai.com" target="_blank" rel="noopener">Jimmy</a> 设计
    </section>
</footer>


    
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    
    <div class="pswp__bg"></div>

    
    <div class="pswp__scroll-wrap">

        
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                
                
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo="crossorigin="anonymous"
                defer
                >
            </script><script 
                src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU="crossorigin="anonymous"
                defer
                >
            </script><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css"crossorigin="anonymous"
            ><link 
                rel="stylesheet" 
                href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css"crossorigin="anonymous"
            >

            </main>
        </div>
        <script 
                src="https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js"integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z&#43;KMkF24hUW8WePSA9HM="crossorigin="anonymous"
                
                >
            </script><script type="text/javascript" src="/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js" defer></script>
<script>
    (function () {
        const customFont = document.createElement('link');
        customFont.href = "https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap";

        customFont.type = "text/css";
        customFont.rel = "stylesheet";

        document.head.appendChild(customFont);
    }());
</script>

    </body>
</html>
