<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Face-Recognition on echudet</title>
        <link>https://echudet.github.io/categories/face-recognition/</link>
        <description>Recent content in Face-Recognition on echudet</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en-us</language>
        <copyright>echudet</copyright>
        <lastBuildDate>Sat, 01 Nov 2025 19:46:45 +0800</lastBuildDate><atom:link href="https://echudet.github.io/categories/face-recognition/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>face-recognition-list</title>
        <link>https://echudet.github.io/p/face-recognition-list/</link>
        <pubDate>Sun, 07 Sep 2025 00:00:00 +0000</pubDate>
        
        <guid>https://echudet.github.io/p/face-recognition-list/</guid>
        <description>&lt;h2 id=&#34;板子性能&#34;&gt;板子性能
&lt;/h2&gt;&lt;p&gt;首先看看板子的性能，确定后面模型算法的选择范围。&lt;/p&gt;
&lt;center class=&#34;half&#34;&gt;
&lt;img src=&#34;board01.png&#34; width=&#34;300&#34;/&gt;
&lt;img src=&#34;board02.png&#34; width=&#34;300&#34;/&gt;
&lt;/center&gt;
&lt;p&gt;从硬件规格来看，Ti60F225板子的关键性能指标包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;片上RAM（325KB）&lt;/strong&gt; - 最高速缓存，用于实时计算&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;HyperRAM（256Mbit=32MB）&lt;/strong&gt; - 高速中等容量存储，可用于模型权重的快速访问&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DDR3（4GB或512MB）&lt;/strong&gt; - 大容量主存储，用于模型、数据库和应用程序&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;SPI Flash（128Mbit=16MB）&lt;/strong&gt; - 非易失性存储，用于存储固件和持久化数据选择原则&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;类比电脑来看&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;名称&lt;/th&gt;
          &lt;th&gt;嵌入式/FPGA角色&lt;/th&gt;
          &lt;th&gt;PC角色&lt;/th&gt;
          &lt;th&gt;用法&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;DDR/SDRAM&lt;/td&gt;
          &lt;td&gt;运行内存/工作区&lt;/td&gt;
          &lt;td&gt;电脑内存条（RAM）&lt;/td&gt;
          &lt;td&gt;随意读写高速&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Flash/NAND&lt;/td&gt;
          &lt;td&gt;固态/持久存储&lt;/td&gt;
          &lt;td&gt;SSD/U盘/硬盘&lt;/td&gt;
          &lt;td&gt;存数据/代码&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;片上RAM&lt;/td&gt;
          &lt;td&gt;高速缓存（KB级别）&lt;/td&gt;
          &lt;td&gt;CPU缓存（Cache）&lt;/td&gt;
          &lt;td&gt;算法Buffer&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;总结来说，我们能用的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;内存（跑模型算法的）： RAM 325KB + HyperRAM 32MB + DDR3 4GB或512MB&lt;/li&gt;
&lt;li&gt;固态存储： Flash 16MB + 任意硬盘/U盘/SDcard X MB&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以一般的模型算法(~几百MB)都能使用，不用过度考虑内存问题。&lt;/p&gt;

&lt;div class=&#34;notice notice-tip&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34; fill=&#34;#437052&#34;&gt;&lt;path d=&#34;M504 256a248 248 0 11-496 0 248 248 0 01496 0zM227 387l184-184c7-6 7-16 0-22l-22-23c-7-6-17-6-23 0L216 308l-70-70c-6-6-16-6-23 0l-22 23c-7 6-7 16 0 22l104 104c6 7 16 7 22 0z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;为什么嵌入式和PC相比，固态存储这么小？&lt;/p&gt;
&lt;p&gt;SPI Flash通常只是用来存放启动镜像、Bootloader、基础的程序等，实际上还需要插tf卡，或者sd卡，或者USB接入U盘。&lt;/p&gt;&lt;/div&gt;

&lt;h2 id=&#34;备选指标&#34;&gt;备选指标
&lt;/h2&gt;&lt;p&gt;广义上来说，人脸识别分为人脸验证($1:1$)和人脸识别($1:N$)两部分。前者只需要根据给定的图片及名字信息来确认他个人的身份，而后者则需要将给定的图片和数据库里面的所有图片进行对比，找出最有可能的身份或确定是否在数据库里面。&lt;/p&gt;
&lt;p&gt;我们要做的人脸识别技术就是后者。不幸的是，后者的难度远远大于前者。粗略估计，倘若对比一次的准确率为$n$，那么人脸验证的准确率为$n$，人脸识别的准确率为$n^k$，其中$k$为数据库里面所含有的图片数量（若$n=0.9,k=10$，那么$n^k = 0.3487$）。因此，我们要注重单次人脸识别的准确度，尽量保证在$0.9$以上。&lt;/p&gt;
&lt;p&gt;另外，板子需要实时处理，对速度要求高。&lt;/p&gt;
&lt;p&gt;除此之外，实现的复杂度、内存和是否CPU亲和也需要考虑。实现复杂度决定了我们能否顺利实现，依赖的环境复不复杂。内存虽然不用过度考虑，但是也不能用过大的模型算法。板子上面没有GPU，因此CPU亲和也非常重要。&lt;/p&gt;
&lt;h2 id=&#34;人脸识别的主要阶段&#34;&gt;人脸识别的主要阶段
&lt;/h2&gt;&lt;p&gt;在传统技术中，人脸识别系统通常包含以下&lt;strong&gt;四个核心阶段&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;首先是&lt;strong&gt;人脸检测&lt;/strong&gt;，这个阶段会在图像中定位人脸的位置，并输出人脸边界框。&lt;/p&gt;
&lt;p&gt;然后是&lt;strong&gt;人脸对齐&lt;/strong&gt;，这个阶段将检测人脸关键点，将人脸归一化到标准的位置和角度，例如偏脸变正脸。&lt;/p&gt;
&lt;p&gt;其次是&lt;strong&gt;特征提取&lt;/strong&gt;，这个阶段会从对齐后的人脸图像提取特征向量，生成能够代表个体身份的特征表示。&lt;/p&gt;
&lt;p&gt;最后是&lt;strong&gt;特征匹配&lt;/strong&gt;，这个阶段将提取的特征与数据库进行对比，完成身份识别。&lt;/p&gt;

&lt;div class=&#34;notice notice-tip&#34; &gt;
    &lt;div class=&#34;notice-title&#34;&gt;&lt;svg xmlns=&#34;http://www.w3.org/2000/svg&#34; class=&#34;icon notice-icon&#34; viewBox=&#34;0 0 512 512&#34; fill=&#34;#437052&#34;&gt;&lt;path d=&#34;M504 256a248 248 0 11-496 0 248 248 0 01496 0zM227 387l184-184c7-6 7-16 0-22l-22-23c-7-6-17-6-23 0L216 308l-70-70c-6-6-16-6-23 0l-22 23c-7 6-7 16 0 22l104 104c6 7 16 7 22 0z&#34;/&gt;&lt;/svg&gt;&lt;/div&gt;&lt;p&gt;简单来说，人脸识别的大致流程是这样的。人脸识别程序T运行在嵌入式设备的RTOS操作系统上面，通过RTOS的摄像外设驱动获取照片P，首先将照片P中可能的人类框选剪切出来(&lt;strong&gt;人脸检测&lt;/strong&gt;)，然后将不同角度的人脸以一定的标准统一化(&lt;strong&gt;人脸对齐&lt;/strong&gt;)，接着从统一后的人脸中提取特征，例如眼睛轮廓等(&lt;strong&gt;特征提取&lt;/strong&gt;)，最后将提取特征的向量和数据库的进行对比，完成身份识别(&lt;strong&gt;特征匹配&lt;/strong&gt;)。&lt;/p&gt;&lt;/div&gt;

&lt;p&gt;（深度学习中，有一些模型能够实现端到端，例如把后面三个阶段直接压缩为一个阶段，这个之后再提）&lt;/p&gt;
&lt;h2 id=&#34;各阶段的主要技术&#34;&gt;各阶段的主要技术
&lt;/h2&gt;&lt;h3 id=&#34;人脸检测阶段&#34;&gt;人脸检测阶段
&lt;/h3&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;技术方法&lt;/th&gt;
          &lt;th&gt;速度&lt;/th&gt;
          &lt;th&gt;准确度&lt;/th&gt;
          &lt;th&gt;实现难度&lt;/th&gt;
          &lt;th&gt;内存需求&lt;/th&gt;
          &lt;th&gt;硬件要求&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;传统方法&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Viola-Jones检测器&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;HOG + SVM&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;DPM&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;深度学习方法&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;MTCNN&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;SSD-Face&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;YOLO-Face系列&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;RetinaFace&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;DSFD&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;CenterFace&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;传统方法方面有三个技术可以使用&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zh.wikipedia.org/wiki/%E7%BB%B4%E5%A5%A5%E6%8B%89-%E7%90%BC%E6%96%AF%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%A1%86%E6%9E%B6&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Viola-Jones检测器&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;第一种可以实时处理并给出良好物体检出率的物体检测技术(虽然有点古老，2001年发表)，主要应用于人脸识别方面。通过分类器的级联来实现目标检测，对单个分类器的误检率要求非常宽容，但对检测率要求较高。&lt;/p&gt;
&lt;p&gt;基于Haar特征和AdaBoost级联分类器。速度极快，可以实时，但准确率较差，需要正脸。&lt;/p&gt;
&lt;p&gt;实现比较简单，可以直接调用opencv现成的库，并且内存需求几mb即可，对硬件要求低。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://juejin.cn/post/6844903614985535501&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;HOG + SVM&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;使用方向梯度直方图特征结合支持向量机。其原理类似于yolo的，但是机器学习。可用yolo取代。&lt;/p&gt;
&lt;p&gt;速度中等，但是准确度比Viola-Jones高，实现需要理解HOG，没有现成的库调用。内存方面需求较低，几十mb即可，普通的CPU可以运行。&lt;/p&gt;
&lt;img src=&#34;hog.png&#34; alt=&#34;hog&#34; style=&#34;zoom: 25%;&#34; /&gt;
&lt;details&gt;
    &lt;summary&gt;what is hog?&lt;/summary&gt;
    &lt;p&gt;方向梯度直方图（Histogram of oriented gradient, HOG）,是抓取图像轮廓线条的算法，现将图片切成很多个区域（Cell）,从每个区域中找出方向梯度，并把它描绘出来，就形成了对象的轮廓，与其他边缘提取的算法比起来，它对环境的变化，如光线有较强的辨识能力。&lt;/p&gt;
&lt;p&gt;使用方向梯度直方图(HOG)来检测人脸位置。先将图片灰度化，接着计算图像中像素的梯度。通过将图像转变成HOG形式，就可以获得人脸位置。&lt;/p&gt;
&lt;p&gt;HOG有一个缺点：&lt;strong&gt;很难处理遮挡问题，人体姿势动作幅度过大或物体方向改变也不易检测&lt;/strong&gt;。&lt;/p&gt;

&lt;/details&gt;

&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://www.cnblogs.com/henuliulei/p/12109100.html&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DPM&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;DPM算法本身是一种基于组件的检测算法，对扭曲，性别，多姿态，多角度等的人脸都有非常好的检测效果。&lt;/p&gt;
&lt;p&gt;DPM算法采用了改进后的HOG特征，SVM分类器和滑动窗口（Sliding Windows）检测思想(属于是前面一个的上位替代，除了速度和内存)。&lt;/p&gt;
&lt;p&gt;速度较慢，准确度在传统方法里面最好，能够辨别变形的人脸，但是实现比较复杂，并且对内存有一定需求，比HOG+SVM需要更多的内存，但具体多少还不确定。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;深度学习方法有六个可以选择&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/595252411&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MTCNN(Multi-task convolutional neural network)&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;多阶段级联CNN，同时检测人脸和关键点。但如果后面使用端到端的模型，这里的关键点是没用的。&lt;/p&gt;
&lt;p&gt;速度快，准确率高，有成熟实现，内存需求约50MB，属于是移动端实时人脸检测的首选（嵌入式也算？）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/zjchenchujie/ssd-face&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SSD-Face&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;基于SSD目标检测框架的人脸检测器。&lt;/p&gt;
&lt;p&gt;单次前传检测所有人脸，速度较快，准确率高，有成熟实现，内存需求为100~200MB，建议使用GPU。&lt;/p&gt;
&lt;p&gt;适合用于同时检测多个人脸的场景（众脸检测）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/YapaLab/yolo-face&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;YOLO-Face系列&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;著名人脸识别模型。&lt;/p&gt;
&lt;p&gt;速度极快，准确率略有牺牲，框架成熟，容易部署。&lt;/p&gt;
&lt;p&gt;内存方面取决于版本，tiny版本仅需20MB且CPU能跑，对于不同版本而言也有更小的。&lt;/p&gt;
&lt;p&gt;也可以一次检测多个人脸，适合“众脸”的场景。&lt;/p&gt;
&lt;p&gt;往年比赛有使用YOLO-v5的，因此可以作为备选。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/serengil/retinaface&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;RetinaFace&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;速度中等，但准确率是目前所有模型中最优的。&lt;/p&gt;
&lt;p&gt;实现需要多任务学习，比较复杂。内存方面需要200MB+，并且使用GPU。&lt;/p&gt;
&lt;p&gt;适合于高精度的应用，例如人脸支付。但是不是很适合众脸识别的项目。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/Tencent/FaceDetection-DSFD&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DSFD&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;速度较慢，但准确率高，小脸检测能力强。&lt;/p&gt;
&lt;p&gt;实现比较复杂，需要完成双路结构。内存方面需要300MB+，并且使用好的GPU。&lt;/p&gt;
&lt;p&gt;适合远距离、小脸检测。&lt;/p&gt;
&lt;p&gt;GPU+复杂实现+高内存+速度慢，不考虑备选。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/Star-Clouds/CenterFace&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CenterFace&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;速度极快，和YOLO相当，准确率中等。&lt;/p&gt;
&lt;p&gt;基于CenterNet，易实现。并且内存方面要求不高，轻量级，&amp;lt;50MB。&lt;/p&gt;
&lt;p&gt;对CPU友好，可以使用CPU顺利运行。&lt;/p&gt;
&lt;p&gt;适合边缘设备、移动端，嵌入式设备本身就是边缘设备的一种？因此可以作为备选。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;人脸对齐阶段&#34;&gt;人脸对齐阶段
&lt;/h3&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;技术方法&lt;/th&gt;
          &lt;th&gt;速度&lt;/th&gt;
          &lt;th&gt;准确度&lt;/th&gt;
          &lt;th&gt;实现难度&lt;/th&gt;
          &lt;th&gt;内存需求&lt;/th&gt;
          &lt;th&gt;硬件要求&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;传统方法&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ASM&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;AAM&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;CLM&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;SDM&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;基于SIFT特征&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;深度学习方法&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;DAN&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;MDM&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;FAN&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;PRNet&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;3DDFA&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;HRNet&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;PFLD&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;传统方法方面有五类方法&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://vibaike.com/174423/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ASM（主动形状模型）&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;ASM主要是通过对形状向量的统计建模来控制合理的形状分布，同时每个单独特征点的局部梯度统计模型，用于在预测迭代时确定点的移动方向和位置。&lt;/p&gt;
&lt;p&gt;速度迭代优化较慢，只考虑形状信息，准确率较低，并且实现非常复杂。&lt;/p&gt;
&lt;p&gt;但是内存硬件需求较低。&lt;/p&gt;
&lt;p&gt;属于是早期研究的产物(1995)，目前已很少使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://vibaike.com/174416/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;AAM（主动外观模型）&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;AAM是一种广泛应用于人脸识别领域的技术。它通过分析人脸图像的几何形状和纹理信息，实现人脸对齐和特征提取。这里实现了两个阶段，但为方便起见，归类于首个阶段。&lt;/p&gt;
&lt;p&gt;比ASM更慢，准确度高一点，实现更加复杂，计算量大。&lt;/p&gt;
&lt;p&gt;属于是近期学术研究的产物，同样不适合使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/delltdk/article/details/49800821&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;CLM（约束局部模型）&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;速度中等，局部特征鲁棒性好，准确率良。&lt;/p&gt;
&lt;p&gt;实现需要多个检测器，难度较高。并且网上搜索用的人较少，参考资料也较少。&lt;/p&gt;
&lt;p&gt;貌似已经被CLNF取代。CLNF速度、准确率均优于CLM。&lt;/p&gt;
&lt;p&gt;内存和硬件要求中等，可以使用cpu。&lt;/p&gt;
&lt;p&gt;适合部分遮挡情况。不推荐使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://dreamocean.github.io/2017/08/03/sdm/&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;SDM（监督下降法）&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;一类机器学习的方法，通过回归的过程实现。对于一张给定的人脸，给出一个初始的形状，通过不断地迭代，将初始形状回归到接近甚至等于真实形状的位置。&lt;/p&gt;
&lt;p&gt;速度快，准确率高，内存需求较小，CPU高效执行。&lt;/p&gt;
&lt;p&gt;嵌入式设备的好选择，如果不用深度学习的话。可作为备选。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/421792422&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;基于SIFT特征的对齐&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;SIFT算法包括两个主要步骤：关键点检测和描述子生成。特征点的检测是指在图像中寻找具有代表性的点作为局部特征点，如角点、边缘、斑点等。这些特征点应具有良好的尺度不变性、旋转不变性和一定的亮度不变性。描述子的生成则是通过分析特征点周围的图像信息，构建一个高维的特征向量来描述每个特征点的局部特征。这使得即使在图像发生一定变化后，这些特征点的描述子仍然可以匹配到一起。&lt;/p&gt;
&lt;p&gt;特征提取慢，但特征点匹配可靠。&lt;/p&gt;
&lt;p&gt;内存需求中等，计算密集。&lt;/p&gt;
&lt;p&gt;适合大姿态变化的场景。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;深度学习方面有四类方法&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/MarekKowalski/DeepAlignmentNetwork&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DAN（深度对齐网络）&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;高效CNN实现，速度较快，级联结构提升精度，准确率也较高。&lt;/p&gt;
&lt;p&gt;实现难度中等，内存需求中等。但是硬件方面更适合用GPU。&lt;/p&gt;
&lt;p&gt;适合通用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/1adrianb/face-alignment&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FAN（人脸对齐网络）&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;沙漏结构，速度比DAN慢。但是准确率非常高。&lt;/p&gt;
&lt;p&gt;内存需求非常大，所以别想了。适合高精度。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/yfeng95/PRNet&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PRNet&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;回归3D人脸位置图，适合3D信息的应用。速度慢，但是准确率高。&lt;/p&gt;
&lt;p&gt;内存要求非常高且GPU必需，故不在考虑范围内。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/73546427&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PFLD（实用人脸关键点检测器）&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;专为速度优化，速度极快。速度优先，故准确率中等。&lt;/p&gt;
&lt;p&gt;结构简单，内存需求&amp;lt;1MB，移动CPU可以跑。属于是移动端首选。&lt;/p&gt;
&lt;p&gt;非常优秀的对齐模型，可作为备选。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;特征提取阶段&#34;&gt;特征提取阶段
&lt;/h3&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;技术方法&lt;/th&gt;
          &lt;th&gt;速度&lt;/th&gt;
          &lt;th&gt;准确度&lt;/th&gt;
          &lt;th&gt;实现难度&lt;/th&gt;
          &lt;th&gt;内存需求&lt;/th&gt;
          &lt;th&gt;硬件要求&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;传统方法&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;PCA/Eigenfaces&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;LDA/Fisherfaces&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ICA&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;LBP&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Gabor小波&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;SIFT/SURF&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;HOG&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;LBPH&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;深度学习方法&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;DeepFace&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;DeepID系列&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;FaceNet&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;VGGFace/VGGFace2&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ResNet-Face&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;MobileFaceNet&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;ArcFace&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;CosFace&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;SphereFace&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;del&gt;AdaFace&lt;/del&gt;&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;传统方法有四个&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/356640804&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;PCA/Eigenfaces&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;老东西，1991年提出。借助 PCA 分析主要成分，对人脸数据进行降维，再进行相关计算，以减少复杂度。&lt;/p&gt;
&lt;p&gt;降维后复杂度低，速度快。但是准确率低。&lt;/p&gt;
&lt;p&gt;实现简单，内存需求少，可运行于CPU。&lt;/p&gt;
&lt;p&gt;适合考古、教学，不适合人脸识别真正使用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/363819175&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;LDA/Fisherfaces&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;LDA与PCA实际上十分类似，LDA和PCA本质上都是对矩阵（人脸）进行降维，并且降维后仍然可以重建人脸。&lt;/p&gt;
&lt;p&gt;它们的不同之处主要在于它们降维目的的不同，PCA降维是朝着”我要最小化重构误差“的思路去降维的，而PCA是朝着”我要最小化类内散度，最大化类间散度“的思路去降维的。换句话说，PCA是为了更好的压缩与重建，而LDA是为了更好地分类。&lt;/p&gt;
&lt;p&gt;需要说明的是，LDA和PCA两种方法对光照都是比较敏感的，如果你用光照均匀的图像作为依据去判别非均匀的，那基本就惨了。&lt;/p&gt;
&lt;p&gt;与PCA相比，速度同样快，准确度和数据库大小有关，但基本比PCA高。&lt;/p&gt;
&lt;p&gt;实现需要类标签，比PCA复杂。内存硬件要求低。&lt;/p&gt;
&lt;p&gt;适合小规模的人脸库。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/166653678&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;LBP（局部二值模式）&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;LBP描述子不仅计算过程相对简单，而且产生的最终效果也不错，因而在学术界和工业界的很多领域都得到了较为广泛的应用。LDA和PCA都是从数据整体入手而不同于LBP提取局部纹理特征。&lt;/p&gt;
&lt;p&gt;速度极快，并且准确率较高。实现简单，内存需求少。&lt;/p&gt;
&lt;p&gt;非常适合于实时系统和嵌入式，加入备选。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/laidefa/Gabor_Face_Recognition&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Gabor小波&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;受采集人脸图像时环境光照等因素影响，传统的代数算法很难达到较高识别率。Gabor 小波变换呈现为频率和方向的多尺度变换，并且与人类视觉感受野剖面非常相似，因此 Gabor 滤波器被用与提取图像局部纹理特征或对整体图像进行卷积得到 Gabor 滤波后的图像。&lt;/p&gt;
&lt;p&gt;总而言之，该方法准确率很高，但是速度慢，内存要求高，计算复杂。&lt;/p&gt;
&lt;p&gt;适合高精度，纹理敏感使用。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;深度学习方面有四个&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/76520981&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;DeepFace&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;中等速度。准确率较高。但是实现难度高，内存需求大，GPU必需。直接排除。&lt;/p&gt;
&lt;p&gt;注意：和github上的deepface项目不是同一个&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/davidsandberg/facenet&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;FaceNet&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;FaceNet的核心思想是学习一个将人脸图像映射到特征向量的函数。Triplet Loss实现，经典的三元组损失。&lt;/p&gt;
&lt;p&gt;速度快，准确率非常高。内存需求中等。适合工业级的应用。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/Xiaoccer/MobileFaceNet_Pytorch&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;MobileFaceNet&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;mobilefacenet是运行在移动设备上的网络，单个网络模型只有4M并且有较高的准确率。&lt;/p&gt;
&lt;p&gt;速度非常快，几乎实时。硬件要求非常低，手机可跑。自然也适合嵌入式环境，备选。&lt;/p&gt;
&lt;p&gt;(不过大部分模型都用python跑，比较麻烦)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/285598652&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;ArcFace/CosFace/SphereFace&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;ArcFace、CosFace、SphereFace是用于人脸识别的先进损失函数，它们通过优化特征空间来提高识别精度。&lt;/p&gt;
&lt;p&gt;推理高效，速度快。准确率当前最优。&lt;/p&gt;
&lt;p&gt;但是实现非常复杂，并且网上没找到现成模型，资料少，内存需求大。适合高精度场景。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;特征匹配与识别阶段&#34;&gt;特征匹配与识别阶段
&lt;/h3&gt;&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;技术方法&lt;/th&gt;
          &lt;th&gt;速度&lt;/th&gt;
          &lt;th&gt;准确度&lt;/th&gt;
          &lt;th&gt;实现难度&lt;/th&gt;
          &lt;th&gt;内存需求&lt;/th&gt;
          &lt;th&gt;硬件要求&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;传统方法&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;欧氏距离&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;马氏距离&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;余弦相似度&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Chi-squared距离&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
          &lt;td&gt;⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;SVM分类器&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;深度学习方法&lt;/strong&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Siamese网络&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Triplet网络&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
          &lt;td&gt;⭐⭐⭐⭐&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;传统方法有三&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;欧式距离&lt;/p&gt;
&lt;p&gt;经典求欧式距离，所有作差再平方。速度最快，准确率中等。&lt;/p&gt;
&lt;p&gt;实现非常简单，并且几乎不占任何内存。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;马氏距离&lt;/p&gt;
&lt;p&gt;考虑特征协方差的距离。速度快，准确率中等。有一定的内存需求。&lt;/p&gt;
&lt;p&gt;评价是不如欧式距离。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;余弦相似度&lt;/p&gt;
&lt;p&gt;余弦相似度是一种衡量两个向量在方向上相似程度的度量，其值域为 [-1, 1]。值越接近1，表示两个向量的方向越接近，即越相似。在人脸比对中，通常会将人脸图像转换为特征向量，然后利用余弦相似度计算这些向量之间的相似度，以此判断两张人脸是否相似。&lt;/p&gt;
&lt;p&gt;速度极快，准确率比欧式距离法高。&lt;/p&gt;
&lt;p&gt;同样实现简单，不占内存。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Chi-squared距离&lt;/p&gt;
&lt;p&gt;适用于直方图特征。速度快，准确率一般。&lt;/p&gt;
&lt;p&gt;实现有点难度，同样不如欧氏距离法。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;SVM分类器&lt;/p&gt;
&lt;p&gt;速度中等，准确率较高。但是机器学习，需要内存调优，并且占用一定量的内存。&lt;/p&gt;
&lt;p&gt;麻烦，不考虑使用。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;深度学习有二&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://zhuanlan.zhihu.com/p/706930791&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Siamese网络&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;这里仅仅用来对比特征数据流，后面会有别的用法。&lt;/p&gt;
&lt;p&gt;单次比较快，准确率较高。实现结构简单，可以使用CPU。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://github.com/andreasveit/triplet-network-pytorch&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;Triplet网络&lt;/a&gt;

&lt;/p&gt;
&lt;p&gt;Triplet网络是一种深度学习模型，主要用于解决样本类别多且训练数据集样本数少的情况，如人脸识别和人脸验证。它是Siamese网络的一种延伸，通过比较距离来学习有用的变量。&lt;/p&gt;
&lt;p&gt;三路输入，所以速度一般，并且内存需求非常高，硬件要求高。但准确率最高。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;组合方案传统&#34;&gt;组合方案（传统）
&lt;/h2&gt;&lt;h3 id=&#34;极简的嵌入方案&#34;&gt;极简的嵌入方案
&lt;/h3&gt;&lt;p&gt;适合于单片机、早期嵌入式设备，可以给嵌入式设备简单测试视觉功能，但是不会参赛真正使用。准确率过低，不适用于众脸识别。&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;阶段&lt;/th&gt;
          &lt;th&gt;技术选择&lt;/th&gt;
          &lt;th&gt;理由&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;检测&lt;/td&gt;
          &lt;td&gt;Viola-Jones&lt;/td&gt;
          &lt;td&gt;速度极快，内存占用极小&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;对齐&lt;/td&gt;
          &lt;td&gt;简单几何归一化&lt;/td&gt;
          &lt;td&gt;仅做基本的眼睛定位和旋转校正&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;特征&lt;/td&gt;
          &lt;td&gt;LBP&lt;/td&gt;
          &lt;td&gt;计算简单，实时性好&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;匹配&lt;/td&gt;
          &lt;td&gt;欧氏距离&lt;/td&gt;
          &lt;td&gt;最简单快速&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;优势&lt;/strong&gt;：可在8位/16位MCU上运行，总内存需求&amp;lt;10MB&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;劣势&lt;/strong&gt;：只适合正面人脸，准确率有限（约70-80%）&lt;/p&gt;
&lt;h3 id=&#34;平衡型传统方案&#34;&gt;平衡型传统方案
&lt;/h3&gt;&lt;p&gt;适用于中端嵌入式平台，准确率有所提升，但仍在90%以下，比较堪忧。&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;阶段&lt;/th&gt;
          &lt;th&gt;技术选择&lt;/th&gt;
          &lt;th&gt;理由&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;检测&lt;/td&gt;
          &lt;td&gt;HOG + SVM&lt;/td&gt;
          &lt;td&gt;准确度和速度的平衡&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;对齐&lt;/td&gt;
          &lt;td&gt;SDM&lt;/td&gt;
          &lt;td&gt;传统方法中最优，速度快&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;特征&lt;/td&gt;
          &lt;td&gt;LBP + PCA&lt;/td&gt;
          &lt;td&gt;LBP提取纹理，PCA降维&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;匹配&lt;/td&gt;
          &lt;td&gt;余弦相似度&lt;/td&gt;
          &lt;td&gt;对特征归一化友好&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;优势&lt;/strong&gt;：纯CPU实现，准确率可达85%左右&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;劣势&lt;/strong&gt;：对光照变化敏感&lt;/p&gt;
&lt;h3 id=&#34;高精度传统方案&#34;&gt;高精度传统方案
&lt;/h3&gt;&lt;p&gt;适用于计算资源充足但不能使用深度学习的场景，实现复杂，速度慢，才仅仅90%准确率，不考虑使用。&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;阶段&lt;/th&gt;
          &lt;th&gt;技术选择&lt;/th&gt;
          &lt;th&gt;理由&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;检测&lt;/td&gt;
          &lt;td&gt;DPM&lt;/td&gt;
          &lt;td&gt;传统方法最准确&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;对齐&lt;/td&gt;
          &lt;td&gt;AAM/CLM&lt;/td&gt;
          &lt;td&gt;考虑纹理信息&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;特征&lt;/td&gt;
          &lt;td&gt;Gabor + LDA&lt;/td&gt;
          &lt;td&gt;多尺度特征+判别分析&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;匹配&lt;/td&gt;
          &lt;td&gt;SVM&lt;/td&gt;
          &lt;td&gt;复杂决策边界&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;优势&lt;/strong&gt;：传统方法的极限，准确率可达90%&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;劣势&lt;/strong&gt;：速度慢，实现复杂&lt;/p&gt;
&lt;h2 id=&#34;组合方案混合&#34;&gt;组合方案（混合）
&lt;/h2&gt;&lt;h3 id=&#34;轻量级混合方案&#34;&gt;轻量级混合方案
&lt;/h3&gt;&lt;p&gt;适合移动设备、边缘计算设备，检测和对齐一体化，减少计算，特征质量高，模型小（&amp;lt;5MB），并且整体准确率&amp;gt;95%，可以作为备选。（只能说模型性能碾压算法）&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;阶段&lt;/th&gt;
          &lt;th&gt;技术选择&lt;/th&gt;
          &lt;th&gt;类型&lt;/th&gt;
          &lt;th&gt;理由&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;检测&lt;/td&gt;
          &lt;td&gt;MTCNN&lt;/td&gt;
          &lt;td&gt;深度学习&lt;/td&gt;
          &lt;td&gt;速度快，同时输出关键点&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;对齐&lt;/td&gt;
          &lt;td&gt;基于MTCNN关键点的仿射变换&lt;/td&gt;
          &lt;td&gt;传统方法&lt;/td&gt;
          &lt;td&gt;利用检测的副产品&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;特征&lt;/td&gt;
          &lt;td&gt;MobileFaceNet&lt;/td&gt;
          &lt;td&gt;深度学习&lt;/td&gt;
          &lt;td&gt;专为移动端设计&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;匹配&lt;/td&gt;
          &lt;td&gt;余弦相似度&lt;/td&gt;
          &lt;td&gt;传统方法&lt;/td&gt;
          &lt;td&gt;简单高效&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;速度优先混合方案&#34;&gt;速度优先混合方案
&lt;/h3&gt;&lt;p&gt;适合实时视频监控、高帧率要求场合，内存占用小，可达100+ FPS，可以作为备选。&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;阶段&lt;/th&gt;
          &lt;th&gt;技术选择&lt;/th&gt;
          &lt;th&gt;类型&lt;/th&gt;
          &lt;th&gt;理由&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;检测&lt;/td&gt;
          &lt;td&gt;YOLO-Fastest&lt;/td&gt;
          &lt;td&gt;深度学习&lt;/td&gt;
          &lt;td&gt;极速检测&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;对齐&lt;/td&gt;
          &lt;td&gt;跳过或简单归一化&lt;/td&gt;
          &lt;td&gt;传统方法&lt;/td&gt;
          &lt;td&gt;节省时间&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;特征&lt;/td&gt;
          &lt;td&gt;LBP&lt;/td&gt;
          &lt;td&gt;传统方法&lt;/td&gt;
          &lt;td&gt;毫秒级提取&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;匹配&lt;/td&gt;
          &lt;td&gt;哈希+汉明距离&lt;/td&gt;
          &lt;td&gt;传统方法&lt;/td&gt;
          &lt;td&gt;二进制匹配极快&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;精度优先混合方案&#34;&gt;精度优先混合方案
&lt;/h3&gt;&lt;p&gt;适用于门禁系统、支付认证这些高精度需求场合，准确率 &amp;gt; 99%，不过准确率这么高，有必要吗？&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;阶段&lt;/th&gt;
          &lt;th&gt;技术选择&lt;/th&gt;
          &lt;th&gt;类型&lt;/th&gt;
          &lt;th&gt;理由&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;检测&lt;/td&gt;
          &lt;td&gt;RetinaFace&lt;/td&gt;
          &lt;td&gt;深度学习&lt;/td&gt;
          &lt;td&gt;最高精度，处理困难情况&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;对齐&lt;/td&gt;
          &lt;td&gt;SDM精细调整&lt;/td&gt;
          &lt;td&gt;传统方法&lt;/td&gt;
          &lt;td&gt;在深度学习基础上微调&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;特征&lt;/td&gt;
          &lt;td&gt;ArcFace&lt;/td&gt;
          &lt;td&gt;深度学习&lt;/td&gt;
          &lt;td&gt;当前最优特征&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;匹配&lt;/td&gt;
          &lt;td&gt;余弦相似度 + SVM验证&lt;/td&gt;
          &lt;td&gt;混合&lt;/td&gt;
          &lt;td&gt;双重验证提高安全性&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;大规模搜索方案&#34;&gt;大规模搜索方案
&lt;/h3&gt;&lt;p&gt;适合百万级人脸库搜索，对硬件要求高，CPU亲和性差，暂时不考虑。&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;阶段&lt;/th&gt;
          &lt;th&gt;技术选择&lt;/th&gt;
          &lt;th&gt;类型&lt;/th&gt;
          &lt;th&gt;理由&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;检测&lt;/td&gt;
          &lt;td&gt;YOLO-Face&lt;/td&gt;
          &lt;td&gt;深度学习&lt;/td&gt;
          &lt;td&gt;批量处理效率高&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;对齐&lt;/td&gt;
          &lt;td&gt;批量仿射变换&lt;/td&gt;
          &lt;td&gt;传统方法&lt;/td&gt;
          &lt;td&gt;GPU并行（但也能CPU跑，不过速度会慢）&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;特征&lt;/td&gt;
          &lt;td&gt;FaceNet&lt;/td&gt;
          &lt;td&gt;深度学习&lt;/td&gt;
          &lt;td&gt;紧凑的128维特征&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;匹配&lt;/td&gt;
          &lt;td&gt;LSH + 余弦相似度&lt;/td&gt;
          &lt;td&gt;混合&lt;/td&gt;
          &lt;td&gt;先粗筛后精匹&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;端到端模型&#34;&gt;端到端模型
&lt;/h2&gt;&lt;p&gt;所谓端到端就是指忽略中间步骤，直接从输入得到输出的过程。&lt;/p&gt;
&lt;p&gt;例如传统人脸识别的后面三个阶段（人脸对齐，特征提取，特征匹配），都可以通过一个人脸图片比较模型来一次性完成。&lt;/p&gt;
&lt;p&gt;例如Siamese检测网络（Siamese-YOLO），将监控图像和数据库图像同时输入，来得到它们的相似度矩阵，从而判断是否是同一个人。&lt;/p&gt;
&lt;h2 id=&#34;跨阶段方案&#34;&gt;跨阶段方案
&lt;/h2&gt;&lt;h3 id=&#34;yolo-face--arcface头&#34;&gt;YOLO-Face + ArcFace头
&lt;/h3&gt;&lt;p&gt;YOLO-Face用于人脸检测，ArcFace（通常指ArcFace loss头，或ArcFace模型）用于人脸特征提取和身份识别。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;速度：40-50 FPS (GPU)，15-20 FPS (CPU)&lt;/li&gt;
&lt;li&gt;准确率：检测 93%，识别 96%&lt;/li&gt;
&lt;li&gt;模型大小：YOLOv5s版本约15MB，总体而言于几十MB这个量级&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;性能方面比较优秀，具体的实现流程也比较简单。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;输入图片或视频帧。&lt;/li&gt;
&lt;li&gt;用YOLO-Face检测所有人脸框。&lt;/li&gt;
&lt;li&gt;对每一个人脸框，截取人脸区域，送入ArcFace模型提特征。&lt;/li&gt;
&lt;li&gt;ArcFace特征与已知身份的人脸特征库做余弦相似度或欧氏距离比对，找出最相似身份（或判定未知）。&lt;/li&gt;
&lt;li&gt;在原图上标注识别结果。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;siamese--mtcnn&#34;&gt;Siamese + MTCNN
&lt;/h3&gt;&lt;p&gt;MTCNN是一个经典的人脸检测与对齐网络，只做检测、定位和人脸关键点，不识别身份。Siamese是一种度量学习方法，擅长进行相似/不同的二分类判断（即1:1比对），可用于面部验证，如A和B是不是同一个人。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;速度：20-25 FPS&lt;/li&gt;
&lt;li&gt;准确率：1:1验证 97%，1:N识别 92%&lt;/li&gt;
&lt;li&gt;模型大小：MTCNN 2MB + Siamese 5MB，个位到十位的量级&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Siamese-MTCNN能够实现特定人脸识别，但通常更适合于“是不是同一个人”（1:1核验），大规模1:N时效率一般。不考虑使用。&lt;/p&gt;
&lt;h3 id=&#34;centerface--mobilefacenet&#34;&gt;CenterFace + MobileFaceNet
&lt;/h3&gt;&lt;p&gt;CenterFace是一种轻量级人脸检测器，能快速准确检测人脸区域。MobileFaceNet是高效的人脸识别特征提取网络，用于提取人脸embedding，并进行身份比对，适合移动端部署。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;速度：60+ FPS (移动GPU)&lt;/li&gt;
&lt;li&gt;准确率：检测 91%，识别 93%&lt;/li&gt;
&lt;li&gt;模型大小：总计不到5MB，个位到十位的量级&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CenterFace和MobileFaceNet合起来，即：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用CenterFace检测人脸；&lt;/li&gt;
&lt;li&gt;用MobileFaceNet提取每个人脸特征；&lt;/li&gt;
&lt;li&gt;跟已有的人脸特征库比对，找出最相似的身份，实现特定身份的识别。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;CenterFace + MobileFaceNet可以很好地实现特定人脸（1:N）识别，效率高，适合实际部署和移动端应用。&lt;/p&gt;
&lt;h3 id=&#34;nanodet--shufflefacenet&#34;&gt;NanoDet + ShuffleFaceNet
&lt;/h3&gt;&lt;p&gt;NanoDet仅1.8MB，ShuffleFaceNet仅2MB，属于是超轻量的模型。适合极限嵌入式环境。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;速度：80+ FPS (ARM CPU)&lt;/li&gt;
&lt;li&gt;准确率：检测 85%，识别 88%&lt;/li&gt;
&lt;li&gt;模型大小：总计&amp;lt;4MB，个位量级&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;板子应该没有这么小？所以不考虑。&lt;/p&gt;
&lt;h2 id=&#34;选取的方案&#34;&gt;选取的方案
&lt;/h2&gt;&lt;p&gt;综上来说，我考虑以下几种方案：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;轻量级混合方案 (MTCNN + 仿射变换 + MobileFaceNet + 余弦相似度)&lt;/p&gt;
&lt;p&gt;这个方案所用的模型小（&amp;lt;5MB），并且整体准确率&amp;gt;95%，速度快，适合嵌入式环境，但是要写一些算法，可能会导致工期变长，并且算法需要额外的FPGA优化，工作量更大。流程变长也意味着出现bug的可能性变大。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;速度优先混合方案(YOLO-Fastest + 跳过或简单归一化 + LBP + 哈希-汉明距离)&lt;/p&gt;
&lt;p&gt;准确率不高（但也不低），但速度很快，适用于实时监测，并且内存占用小。实际上是四个方案中最末的方案，不高准确率意味着人脸识别的效果不会很好，倘若嵌入环境比理论的更糟糕才考虑的方案。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;YOLO-Face + ArcFace头&lt;/p&gt;
&lt;p&gt;速度快，准确率达90%+，内存小，优秀的工作流。&lt;/p&gt;
&lt;p&gt;两个都属于模型，方便FPGA统一优化，一旦完成了其中一个模型的执行流，另外一个也差不多了。&lt;/p&gt;
&lt;p&gt;最推荐的方案，YOLO这些模型所用的领域非常广，因此各个方面对它的支持是最多的，开发起来最为便捷。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;CenterFace + MobileFaceNet&lt;/p&gt;
&lt;p&gt;同样速度快，准确率高，内存小，两个都属于模型，方便FPGA统一优化。&lt;/p&gt;
&lt;p&gt;并且可以很好地实现特定人脸（1:N）识别，效率高，适合实际部署和移动端应用。&lt;/p&gt;
&lt;p&gt;作为方案三的备选，有着和方案三差不多的效果。但是模型不如方案三知名。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
</description>
        </item>
        
    </channel>
</rss>
